{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with Gemini 3 Pro\n",
    "\n",
    "> **Created by [Build Fast with AI](https://www.buildfastwithai.com)**\n",
    "\n",
    "This notebook will guide you through the basics of using Google's Gemini 3 Pro model with the Google Generative AI SDK.\n",
    "\n",
    "## What you'll learn:\n",
    "- Setting up the Google Generative AI SDK\n",
    "- Making your first API call\n",
    "- Understanding model parameters\n",
    "- Working with different types of prompts\n",
    "- Handling responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installation and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the Google Generative AI SDK\n",
    "!pip install -q google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configure API Key\n",
    "\n",
    "Get your API key from [Google AI Studio](https://makersuite.google.com/app/apikey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Google Colab, use userdata to store your API key securely\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
    "except:\n",
    "    # For local development\n",
    "    GOOGLE_API_KEY = os.environ.get('GOOGLE_API_KEY', 'your-api-key-here')\n",
    "\n",
    "# Configure the SDK\n",
    "genai.configure(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Your First API Call\n",
    "\n",
    "Let's start with a simple text generation example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model = genai.GenerativeModel('gemini-3-pro')\n",
    "\n",
    "# Generate content\n",
    "response = model.generate_content(\"Explain artificial intelligence in simple terms.\")\n",
    "\n",
    "# Display the response\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Understanding Model Parameters\n",
    "\n",
    "Gemini 3 Pro supports various parameters to control the generation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure generation parameters\n",
    "generation_config = {\n",
    "    \"temperature\": 0.9,  # Controls randomness (0.0 to 1.0)\n",
    "    \"top_p\": 0.95,       # Controls diversity via nucleus sampling\n",
    "    \"top_k\": 40,         # Controls diversity via top-k sampling\n",
    "    \"max_output_tokens\": 2048,  # Maximum length of response\n",
    "}\n",
    "\n",
    "# Initialize model with configuration\n",
    "model = genai.GenerativeModel(\n",
    "    'gemini-3-pro',\n",
    "    generation_config=generation_config\n",
    ")\n",
    "\n",
    "response = model.generate_content(\"Write a creative short story about a robot learning to paint.\")\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Working with System Instructions\n",
    "\n",
    "System instructions help guide the model's behavior and persona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model with system instructions\n",
    "model = genai.GenerativeModel(\n",
    "    'gemini-3-pro',\n",
    "    system_instruction=\"You are a helpful Python programming tutor. \"\n",
    "                      \"Explain concepts clearly with code examples.\"\n",
    ")\n",
    "\n",
    "response = model.generate_content(\"How do list comprehensions work in Python?\")\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Multi-turn Conversations\n",
    "\n",
    "Gemini 3 Pro excels at maintaining context across multiple interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a chat session\n",
    "model = genai.GenerativeModel('gemini-3-pro')\n",
    "chat = model.start_chat(history=[])\n",
    "\n",
    "# First message\n",
    "response1 = chat.send_message(\"What is machine learning?\")\n",
    "print(\"User: What is machine learning?\")\n",
    "display(Markdown(response1.text))\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Follow-up question (model remembers context)\n",
    "response2 = chat.send_message(\"Can you give me a practical example?\")\n",
    "print(\"User: Can you give me a practical example?\")\n",
    "display(Markdown(response2.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Handling Safety Settings\n",
    "\n",
    "Configure safety settings to control content filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.generativeai.types import HarmCategory, HarmBlockThreshold\n",
    "\n",
    "safety_settings = [\n",
    "    {\n",
    "        \"category\": HarmCategory.HARM_CATEGORY_HARASSMENT,\n",
    "        \"threshold\": HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
    "    },\n",
    "    {\n",
    "        \"category\": HarmCategory.HARM_CATEGORY_HATE_SPEECH,\n",
    "        \"threshold\": HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
    "    },\n",
    "]\n",
    "\n",
    "model = genai.GenerativeModel(\n",
    "    'gemini-3-pro',\n",
    "    safety_settings=safety_settings\n",
    ")\n",
    "\n",
    "response = model.generate_content(\"Tell me about online safety.\")\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Accessing Response Metadata\n",
    "\n",
    "You can access various metadata about the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel('gemini-3-pro')\n",
    "response = model.generate_content(\"Explain quantum computing briefly.\")\n",
    "\n",
    "print(\"Response text:\")\n",
    "display(Markdown(response.text))\n",
    "\n",
    "print(\"\\nMetadata:\")\n",
    "print(f\"Prompt feedback: {response.prompt_feedback}\")\n",
    "print(f\"\\nCandidate count: {len(response.candidates)}\")\n",
    "print(f\"Finish reason: {response.candidates[0].finish_reason}\")\n",
    "print(f\"Safety ratings: {response.candidates[0].safety_ratings}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Error Handling Best Practices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_with_retry(prompt, max_retries=3):\n",
    "    \"\"\"Generate content with retry logic\"\"\"\n",
    "    model = genai.GenerativeModel('gemini-3-pro')\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = model.generate_content(prompt)\n",
    "            return response.text\n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt + 1} failed: {str(e)}\")\n",
    "            if attempt == max_retries - 1:\n",
    "                raise\n",
    "            import time\n",
    "            time.sleep(2 ** attempt)  # Exponential backoff\n",
    "\n",
    "# Test the function\n",
    "result = generate_with_retry(\"What is the capital of France?\")\n",
    "display(Markdown(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Practical Example: Building a Simple Q&A System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeminiQA:\n",
    "    def __init__(self, context=\"\"):\n",
    "        self.model = genai.GenerativeModel(\n",
    "            'gemini-3-pro',\n",
    "            system_instruction=f\"You are a helpful assistant. {context}\"\n",
    "        )\n",
    "        self.chat = self.model.start_chat(history=[])\n",
    "    \n",
    "    def ask(self, question):\n",
    "        \"\"\"Ask a question and get a response\"\"\"\n",
    "        response = self.chat.send_message(question)\n",
    "        return response.text\n",
    "    \n",
    "    def get_history(self):\n",
    "        \"\"\"Get conversation history\"\"\"\n",
    "        return self.chat.history\n",
    "\n",
    "# Create a QA system for Python programming\n",
    "qa_system = GeminiQA(context=\"You specialize in Python programming and best practices.\")\n",
    "\n",
    "# Ask some questions\n",
    "questions = [\n",
    "    \"What are decorators in Python?\",\n",
    "    \"Can you show me an example?\",\n",
    "    \"What are common use cases?\"\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    print(f\"\\n**Q: {question}**\")\n",
    "    answer = qa_system.ask(question)\n",
    "    display(Markdown(answer))\n",
    "    print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Now that you understand the basics, explore:\n",
    "- **Advanced Features**: Streaming, function calling, and more\n",
    "- **RAG**: Building retrieval-augmented generation systems\n",
    "- **Agents**: Creating autonomous AI agents\n",
    "- **Streamlit Apps**: Building interactive applications\n",
    "\n",
    "---\n",
    "\n",
    "## Learn More\n",
    "\n",
    "Want to dive deeper into Generative AI? Check out the **[Gen AI Crash Course](https://www.buildfastwithai.com/genai-course)** by Build Fast with AI!\n",
    "\n",
    "**Created by [Build Fast with AI](https://www.buildfastwithai.com)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
