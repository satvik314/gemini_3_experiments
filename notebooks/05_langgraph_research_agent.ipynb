{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangGraph Research Assistant Agent\n",
    "\n",
    "> **Created by [Build Fast with AI](https://www.buildfastwithai.com)**\n",
    "\n",
    "This notebook demonstrates how to build a research assistant agent using LangGraph and Gemini 3 Pro.\n",
    "\n",
    "## What you'll learn:\n",
    "- Introduction to LangGraph\n",
    "- Creating stateful agents\n",
    "- Building tool-using agents\n",
    "- Implementing agent reasoning loops\n",
    "- Error handling in agent workflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q langgraph langchain langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import TypedDict, Annotated, List\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.tools import tool\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.prebuilt import ToolExecutor, ToolInvocation\n",
    "from IPython.display import Image, display, Markdown\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure API key\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
    "except:\n",
    "    GOOGLE_API_KEY = os.environ.get('GOOGLE_API_KEY', 'your-api-key-here')\n",
    "\n",
    "os.environ['GOOGLE_API_KEY'] = GOOGLE_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define Research Tools\n",
    "\n",
    "First, let's create tools that our agent can use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def search_arxiv(query: str) -> str:\n",
    "    \"\"\"Search for academic papers on ArXiv.\n",
    "    \n",
    "    Args:\n",
    "        query: The search query for papers\n",
    "    \n",
    "    Returns:\n",
    "        String containing paper information\n",
    "    \"\"\"\n",
    "    # Simulated search results\n",
    "    papers = [\n",
    "        {\n",
    "            \"title\": \"Attention Is All You Need\",\n",
    "            \"authors\": \"Vaswani et al.\",\n",
    "            \"year\": 2017,\n",
    "            \"summary\": \"Introduced the Transformer architecture for neural networks.\"\n",
    "        },\n",
    "        {\n",
    "            \"title\": \"BERT: Pre-training of Deep Bidirectional Transformers\",\n",
    "            \"authors\": \"Devlin et al.\",\n",
    "            \"year\": 2018,\n",
    "            \"summary\": \"Introduced BERT, a bidirectional transformer for NLP.\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    results = f\"Found {len(papers)} papers for '{query}':\\n\\n\"\n",
    "    for i, paper in enumerate(papers, 1):\n",
    "        results += f\"{i}. {paper['title']} ({paper['year']})\\n\"\n",
    "        results += f\"   Authors: {paper['authors']}\\n\"\n",
    "        results += f\"   Summary: {paper['summary']}\\n\\n\"\n",
    "    \n",
    "    return results\n",
    "\n",
    "@tool\n",
    "def search_web(query: str) -> str:\n",
    "    \"\"\"Search the web for information.\n",
    "    \n",
    "    Args:\n",
    "        query: The search query\n",
    "    \n",
    "    Returns:\n",
    "        String containing search results\n",
    "    \"\"\"\n",
    "    # Simulated web search\n",
    "    return f\"\"\"Web search results for '{query}':\n",
    "    \n",
    "1. Wikipedia: Comprehensive article about {query}\n",
    "2. Official Documentation: Technical details and API reference\n",
    "3. Tutorial: Step-by-step guide for beginners\n",
    "4. Research Blog: Latest developments and insights\n",
    "\"\"\"\n",
    "\n",
    "@tool\n",
    "def calculate(expression: str) -> str:\n",
    "    \"\"\"Evaluate a mathematical expression.\n",
    "    \n",
    "    Args:\n",
    "        expression: Mathematical expression to evaluate\n",
    "    \n",
    "    Returns:\n",
    "        The result of the calculation\n",
    "    \"\"\"\n",
    "    try:\n",
    "        result = eval(expression)\n",
    "        return f\"Result: {result}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def summarize_text(text: str) -> str:\n",
    "    \"\"\"Summarize a long text.\n",
    "    \n",
    "    Args:\n",
    "        text: The text to summarize\n",
    "    \n",
    "    Returns:\n",
    "        A summary of the text\n",
    "    \"\"\"\n",
    "    # Simple summarization (in production, use LLM)\n",
    "    words = text.split()\n",
    "    if len(words) > 50:\n",
    "        summary = ' '.join(words[:50]) + \"...\"\n",
    "    else:\n",
    "        summary = text\n",
    "    return f\"Summary: {summary}\"\n",
    "\n",
    "# List of all tools\n",
    "tools = [search_arxiv, search_web, calculate, summarize_text]\n",
    "\n",
    "print(f\"Created {len(tools)} tools for the agent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Agent State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    \"\"\"State of the research agent.\"\"\"\n",
    "    messages: List[dict]\n",
    "    next_action: str\n",
    "    intermediate_steps: List[dict]\n",
    "    final_answer: str\n",
    "\n",
    "print(\"Agent state defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initialize LLM and Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Gemini\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-3-pro\",\n",
    "    temperature=0.7,\n",
    "    google_api_key=GOOGLE_API_KEY\n",
    ")\n",
    "\n",
    "# Bind tools to LLM\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "print(\"LLM initialized with tools\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define Agent Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"The agent decides what to do next.\"\"\"\n",
    "    messages = state['messages']\n",
    "    \n",
    "    # Get the last message\n",
    "    last_message = messages[-1] if messages else {\"role\": \"user\", \"content\": \"\"}\n",
    "    \n",
    "    # Call LLM\n",
    "    response = llm_with_tools.invoke([\n",
    "        {\"role\": msg[\"role\"], \"content\": msg[\"content\"]}\n",
    "        for msg in messages\n",
    "    ])\n",
    "    \n",
    "    # Update state\n",
    "    state['messages'].append({\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": response.content\n",
    "    })\n",
    "    \n",
    "    # Check if tool calls are needed\n",
    "    if hasattr(response, 'tool_calls') and response.tool_calls:\n",
    "        state['next_action'] = 'tools'\n",
    "        state['intermediate_steps'].append({\n",
    "            \"tool_calls\": response.tool_calls\n",
    "        })\n",
    "    else:\n",
    "        state['next_action'] = 'end'\n",
    "        state['final_answer'] = response.content\n",
    "    \n",
    "    return state\n",
    "\n",
    "def tool_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"Execute tools.\"\"\"\n",
    "    last_step = state['intermediate_steps'][-1]\n",
    "    tool_calls = last_step.get('tool_calls', [])\n",
    "    \n",
    "    # Execute each tool\n",
    "    tool_results = []\n",
    "    for tool_call in tool_calls:\n",
    "        tool_name = tool_call['name']\n",
    "        tool_args = tool_call['args']\n",
    "        \n",
    "        # Find and execute tool\n",
    "        for tool in tools:\n",
    "            if tool.name == tool_name:\n",
    "                result = tool.invoke(tool_args)\n",
    "                tool_results.append({\n",
    "                    \"tool\": tool_name,\n",
    "                    \"result\": result\n",
    "                })\n",
    "    \n",
    "    # Add results to messages\n",
    "    results_text = \"\\n\\n\".join([\n",
    "        f\"Tool: {r['tool']}\\nResult: {r['result']}\"\n",
    "        for r in tool_results\n",
    "    ])\n",
    "    \n",
    "    state['messages'].append({\n",
    "        \"role\": \"system\",\n",
    "        \"content\": f\"Tool results:\\n{results_text}\"\n",
    "    })\n",
    "    \n",
    "    state['next_action'] = 'agent'\n",
    "    \n",
    "    return state\n",
    "\n",
    "def should_continue(state: AgentState) -> str:\n",
    "    \"\"\"Determine next step.\"\"\"\n",
    "    return state.get('next_action', 'end')\n",
    "\n",
    "print(\"Agent nodes defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Build the Agent Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the graph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"agent\", agent_node)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "\n",
    "# Set entry point\n",
    "workflow.set_entry_point(\"agent\")\n",
    "\n",
    "# Add conditional edges\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"tools\": \"tools\",\n",
    "        \"end\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add edge from tools back to agent\n",
    "workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "# Compile the graph\n",
    "app = workflow.compile()\n",
    "\n",
    "print(\"Agent graph built successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Run the Research Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_research_agent(query: str):\n",
    "    \"\"\"Run the research agent with a query.\"\"\"\n",
    "    # Initialize state\n",
    "    initial_state = {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": query\n",
    "            }\n",
    "        ],\n",
    "        \"next_action\": \"agent\",\n",
    "        \"intermediate_steps\": [],\n",
    "        \"final_answer\": \"\"\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Research Query: {query}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # Run the agent\n",
    "    result = app.invoke(initial_state)\n",
    "    \n",
    "    # Display results\n",
    "    print(\"\\nAgent Thought Process:\")\n",
    "    for i, msg in enumerate(result['messages'], 1):\n",
    "        role = msg['role'].upper()\n",
    "        content = msg['content']\n",
    "        print(f\"\\n[{role}]:\")\n",
    "        print(content[:300] + \"...\" if len(content) > 300 else content)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"\\nFinal Answer:\")\n",
    "    display(Markdown(result.get('final_answer', 'No final answer generated')))\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Test the agent\n",
    "result = run_research_agent(\n",
    "    \"What are the key innovations in transformer architecture? Search for papers and summarize.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Advanced Agent with Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResearchAssistant:\n",
    "    \"\"\"A stateful research assistant.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.conversation_history = []\n",
    "        self.research_notes = []\n",
    "    \n",
    "    def research(self, query: str, save_notes: bool = True):\n",
    "        \"\"\"Perform research on a query.\"\"\"\n",
    "        # Add to conversation history\n",
    "        self.conversation_history.append({\n",
    "            \"role\": \"user\",\n",
    "            \"content\": query\n",
    "        })\n",
    "        \n",
    "        # Initialize state with history\n",
    "        initial_state = {\n",
    "            \"messages\": self.conversation_history.copy(),\n",
    "            \"next_action\": \"agent\",\n",
    "            \"intermediate_steps\": [],\n",
    "            \"final_answer\": \"\"\n",
    "        }\n",
    "        \n",
    "        # Run agent\n",
    "        result = app.invoke(initial_state)\n",
    "        \n",
    "        # Update history\n",
    "        self.conversation_history = result['messages']\n",
    "        \n",
    "        # Save research notes\n",
    "        if save_notes and result.get('final_answer'):\n",
    "            self.research_notes.append({\n",
    "                \"query\": query,\n",
    "                \"answer\": result['final_answer'],\n",
    "                \"tools_used\": len(result['intermediate_steps'])\n",
    "            })\n",
    "        \n",
    "        return result['final_answer']\n",
    "    \n",
    "    def get_notes(self):\n",
    "        \"\"\"Get all research notes.\"\"\"\n",
    "        return self.research_notes\n",
    "    \n",
    "    def clear_history(self):\n",
    "        \"\"\"Clear conversation history.\"\"\"\n",
    "        self.conversation_history = []\n",
    "        print(\"History cleared\")\n",
    "\n",
    "# Create assistant\n",
    "assistant = ResearchAssistant()\n",
    "\n",
    "# Test with multiple queries\n",
    "queries = [\n",
    "    \"Search for information about transformers in AI\",\n",
    "    \"What papers did you find?\",\n",
    "    \"Can you summarize the key points?\"\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Query: {query}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    answer = assistant.research(query)\n",
    "    display(Markdown(answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. View Research Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Research Notes Summary:\\n\")\n",
    "notes = assistant.get_notes()\n",
    "\n",
    "for i, note in enumerate(notes, 1):\n",
    "    print(f\"{i}. Query: {note['query']}\")\n",
    "    print(f\"   Tools used: {note['tools_used']}\")\n",
    "    print(f\"   Answer preview: {note['answer'][:100]}...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Error Handling in Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_agent_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"Agent node with error handling.\"\"\"\n",
    "    try:\n",
    "        return agent_node(state)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in agent: {str(e)}\")\n",
    "        state['next_action'] = 'end'\n",
    "        state['final_answer'] = f\"Error occurred: {str(e)}\"\n",
    "        return state\n",
    "\n",
    "def safe_tool_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"Tool node with error handling.\"\"\"\n",
    "    try:\n",
    "        return tool_node(state)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in tool execution: {str(e)}\")\n",
    "        state['messages'].append({\n",
    "            \"role\": \"system\",\n",
    "            \"content\": f\"Tool execution failed: {str(e)}\"\n",
    "        })\n",
    "        state['next_action'] = 'agent'\n",
    "        return state\n",
    "\n",
    "print(\"Safe agent nodes defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Best Practices for LangGraph Agents\n",
    "\n",
    "### Key Considerations:\n",
    "\n",
    "1. **State Management**: Keep state minimal and well-structured\n",
    "2. **Tool Design**: Make tools focused and reusable\n",
    "3. **Error Handling**: Always handle errors gracefully\n",
    "4. **Logging**: Log agent decisions for debugging\n",
    "5. **Testing**: Test each node independently\n",
    "6. **Limits**: Set maximum iterations to prevent infinite loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- Build multi-agent systems with CrewAI\n",
    "- Create autonomous agents for complex tasks\n",
    "- Deploy agents in production with Streamlit\n",
    "\n",
    "---\n",
    "\n",
    "## Learn More\n",
    "\n",
    "Master agent development with the **[Gen AI Crash Course](https://www.buildfastwithai.com/genai-course)** by Build Fast with AI!\n",
    "\n",
    "**Created by [Build Fast with AI](https://www.buildfastwithai.com)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
