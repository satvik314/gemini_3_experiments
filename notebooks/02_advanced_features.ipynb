{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Features: Streaming & Function Calling\n",
    "\n",
    "> **Created by [Build Fast with AI](https://www.buildfastwithai.com)**\n",
    "\n",
    "This notebook explores advanced features of Gemini 3 Pro including streaming responses and function calling.\n",
    "\n",
    "## What you'll learn:\n",
    "- Streaming responses for better UX\n",
    "- Function calling (tool use)\n",
    "- Multi-turn function calling\n",
    "- Structured output generation\n",
    "- Advanced error handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "import json\n",
    "from IPython.display import Markdown, display\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure API key\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
    "except:\n",
    "    GOOGLE_API_KEY = os.environ.get('GOOGLE_API_KEY', 'your-api-key-here')\n",
    "\n",
    "genai.configure(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Streaming Responses\n",
    "\n",
    "Streaming allows you to display partial results as they're generated, improving user experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel('gemini-3-pro')\n",
    "\n",
    "prompt = \"Write a detailed explanation of how neural networks work.\"\n",
    "\n",
    "print(\"Streaming response:\\n\")\n",
    "response = model.generate_content(prompt, stream=True)\n",
    "\n",
    "for chunk in response:\n",
    "    print(chunk.text, end='', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Streaming with Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel('gemini-3-pro')\n",
    "chat = model.start_chat(history=[])\n",
    "\n",
    "print(\"User: Explain quantum computing\\n\")\n",
    "print(\"Assistant: \", end='')\n",
    "\n",
    "response = chat.send_message(\"Explain quantum computing\", stream=True)\n",
    "\n",
    "for chunk in response:\n",
    "    print(chunk.text, end='', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Function Calling Basics\n",
    "\n",
    "Function calling allows Gemini to interact with external tools and APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that the model can call\n",
    "def get_weather(location: str, unit: str = \"celsius\") -> dict:\n",
    "    \"\"\"Get the weather for a location.\n",
    "    \n",
    "    Args:\n",
    "        location: The city and country, e.g., 'London, UK'\n",
    "        unit: Temperature unit, 'celsius' or 'fahrenheit'\n",
    "    \n",
    "    Returns:\n",
    "        Weather information dictionary\n",
    "    \"\"\"\n",
    "    # Simulated weather data\n",
    "    weather_data = {\n",
    "        \"location\": location,\n",
    "        \"temperature\": 22 if unit == \"celsius\" else 72,\n",
    "        \"unit\": unit,\n",
    "        \"condition\": \"Partly cloudy\",\n",
    "        \"humidity\": 65,\n",
    "        \"wind_speed\": 15\n",
    "    }\n",
    "    return weather_data\n",
    "\n",
    "# Define the function schema for Gemini\n",
    "weather_function = genai.protos.FunctionDeclaration(\n",
    "    name=\"get_weather\",\n",
    "    description=\"Get the current weather for a location\",\n",
    "    parameters=genai.protos.Schema(\n",
    "        type=genai.protos.Type.OBJECT,\n",
    "        properties={\n",
    "            \"location\": genai.protos.Schema(\n",
    "                type=genai.protos.Type.STRING,\n",
    "                description=\"The city and country, e.g., 'London, UK'\"\n",
    "            ),\n",
    "            \"unit\": genai.protos.Schema(\n",
    "                type=genai.protos.Type.STRING,\n",
    "                description=\"Temperature unit, 'celsius' or 'fahrenheit'\",\n",
    "                enum=[\"celsius\", \"fahrenheit\"]\n",
    "            )\n",
    "        },\n",
    "        required=[\"location\"]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tool with the function\n",
    "weather_tool = genai.protos.Tool(\n",
    "    function_declarations=[weather_function]\n",
    ")\n",
    "\n",
    "# Initialize model with the tool\n",
    "model = genai.GenerativeModel(\n",
    "    'gemini-3-pro',\n",
    "    tools=[weather_tool]\n",
    ")\n",
    "\n",
    "# Ask a question that requires the function\n",
    "chat = model.start_chat()\n",
    "response = chat.send_message(\"What's the weather like in Tokyo?\")\n",
    "\n",
    "# Check if model wants to call a function\n",
    "if response.candidates[0].content.parts[0].function_call:\n",
    "    function_call = response.candidates[0].content.parts[0].function_call\n",
    "    print(f\"Model wants to call: {function_call.name}\")\n",
    "    print(f\"With arguments: {dict(function_call.args)}\")\n",
    "    \n",
    "    # Execute the function\n",
    "    if function_call.name == \"get_weather\":\n",
    "        result = get_weather(**dict(function_call.args))\n",
    "        print(f\"\\nFunction result: {result}\")\n",
    "        \n",
    "        # Send result back to model\n",
    "        response = chat.send_message(\n",
    "            genai.protos.Content(\n",
    "                parts=[genai.protos.Part(\n",
    "                    function_response=genai.protos.FunctionResponse(\n",
    "                        name=\"get_weather\",\n",
    "                        response={\"result\": result}\n",
    "                    )\n",
    "                )]\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        print(\"\\nFinal response:\")\n",
    "        display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Multiple Function Declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define multiple functions\n",
    "def calculate_bmi(weight_kg: float, height_m: float) -> dict:\n",
    "    \"\"\"Calculate Body Mass Index.\"\"\"\n",
    "    bmi = weight_kg / (height_m ** 2)\n",
    "    if bmi < 18.5:\n",
    "        category = \"Underweight\"\n",
    "    elif bmi < 25:\n",
    "        category = \"Normal weight\"\n",
    "    elif bmi < 30:\n",
    "        category = \"Overweight\"\n",
    "    else:\n",
    "        category = \"Obese\"\n",
    "    \n",
    "    return {\n",
    "        \"bmi\": round(bmi, 2),\n",
    "        \"category\": category\n",
    "    }\n",
    "\n",
    "def convert_temperature(value: float, from_unit: str, to_unit: str) -> float:\n",
    "    \"\"\"Convert temperature between units.\"\"\"\n",
    "    if from_unit == \"celsius\" and to_unit == \"fahrenheit\":\n",
    "        return (value * 9/5) + 32\n",
    "    elif from_unit == \"fahrenheit\" and to_unit == \"celsius\":\n",
    "        return (value - 32) * 5/9\n",
    "    else:\n",
    "        return value\n",
    "\n",
    "# Define function schemas\n",
    "bmi_function = genai.protos.FunctionDeclaration(\n",
    "    name=\"calculate_bmi\",\n",
    "    description=\"Calculate Body Mass Index from weight and height\",\n",
    "    parameters=genai.protos.Schema(\n",
    "        type=genai.protos.Type.OBJECT,\n",
    "        properties={\n",
    "            \"weight_kg\": genai.protos.Schema(type=genai.protos.Type.NUMBER),\n",
    "            \"height_m\": genai.protos.Schema(type=genai.protos.Type.NUMBER)\n",
    "        },\n",
    "        required=[\"weight_kg\", \"height_m\"]\n",
    "    )\n",
    ")\n",
    "\n",
    "temp_function = genai.protos.FunctionDeclaration(\n",
    "    name=\"convert_temperature\",\n",
    "    description=\"Convert temperature between Celsius and Fahrenheit\",\n",
    "    parameters=genai.protos.Schema(\n",
    "        type=genai.protos.Type.OBJECT,\n",
    "        properties={\n",
    "            \"value\": genai.protos.Schema(type=genai.protos.Type.NUMBER),\n",
    "            \"from_unit\": genai.protos.Schema(\n",
    "                type=genai.protos.Type.STRING,\n",
    "                enum=[\"celsius\", \"fahrenheit\"]\n",
    "            ),\n",
    "            \"to_unit\": genai.protos.Schema(\n",
    "                type=genai.protos.Type.STRING,\n",
    "                enum=[\"celsius\", \"fahrenheit\"]\n",
    "            )\n",
    "        },\n",
    "        required=[\"value\", \"from_unit\", \"to_unit\"]\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create tools\n",
    "tools = genai.protos.Tool(\n",
    "    function_declarations=[bmi_function, temp_function]\n",
    ")\n",
    "\n",
    "model = genai.GenerativeModel('gemini-3-pro', tools=[tools])\n",
    "print(\"Model initialized with multiple functions!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Automatic Function Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_function_call(function_call):\n",
    "    \"\"\"Execute a function call and return the result.\"\"\"\n",
    "    function_name = function_call.name\n",
    "    function_args = dict(function_call.args)\n",
    "    \n",
    "    # Map function names to actual functions\n",
    "    available_functions = {\n",
    "        \"get_weather\": get_weather,\n",
    "        \"calculate_bmi\": calculate_bmi,\n",
    "        \"convert_temperature\": convert_temperature\n",
    "    }\n",
    "    \n",
    "    if function_name in available_functions:\n",
    "        return available_functions[function_name](**function_args)\n",
    "    else:\n",
    "        return {\"error\": f\"Function {function_name} not found\"}\n",
    "\n",
    "# Test with automatic execution\n",
    "chat = model.start_chat()\n",
    "user_message = \"Convert 25 degrees Celsius to Fahrenheit\"\n",
    "print(f\"User: {user_message}\\n\")\n",
    "\n",
    "response = chat.send_message(user_message)\n",
    "\n",
    "# Handle function calls automatically\n",
    "while response.candidates[0].content.parts[0].function_call:\n",
    "    function_call = response.candidates[0].content.parts[0].function_call\n",
    "    print(f\"Calling function: {function_call.name}\")\n",
    "    print(f\"Arguments: {dict(function_call.args)}\\n\")\n",
    "    \n",
    "    # Execute function\n",
    "    result = execute_function_call(function_call)\n",
    "    print(f\"Result: {result}\\n\")\n",
    "    \n",
    "    # Send result back\n",
    "    response = chat.send_message(\n",
    "        genai.protos.Content(\n",
    "            parts=[genai.protos.Part(\n",
    "                function_response=genai.protos.FunctionResponse(\n",
    "                    name=function_call.name,\n",
    "                    response={\"result\": result}\n",
    "                )\n",
    "            )]\n",
    "        )\n",
    "    )\n",
    "\n",
    "print(\"Assistant response:\")\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. JSON Mode for Structured Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure model for JSON output\n",
    "model = genai.GenerativeModel(\n",
    "    'gemini-3-pro',\n",
    "    generation_config={\n",
    "        \"response_mime_type\": \"application/json\"\n",
    "    }\n",
    ")\n",
    "\n",
    "prompt = \"\"\"\n",
    "Generate a user profile with the following fields:\n",
    "- name\n",
    "- age\n",
    "- occupation\n",
    "- hobbies (list)\n",
    "- address (object with street, city, country)\n",
    "\n",
    "Create a profile for a software engineer.\n",
    "\"\"\"\n",
    "\n",
    "response = model.generate_content(prompt)\n",
    "user_profile = json.loads(response.text)\n",
    "\n",
    "print(\"Generated User Profile:\")\n",
    "print(json.dumps(user_profile, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Combining Streaming with Function Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel(\n",
    "    'gemini-3-pro',\n",
    "    tools=[genai.protos.Tool(function_declarations=[weather_function])]\n",
    ")\n",
    "\n",
    "chat = model.start_chat()\n",
    "print(\"User: What's the weather in Paris and should I bring an umbrella?\\n\")\n",
    "print(\"Assistant: \", end='')\n",
    "\n",
    "response = chat.send_message(\n",
    "    \"What's the weather in Paris and should I bring an umbrella?\",\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "function_calls = []\n",
    "for chunk in response:\n",
    "    if chunk.candidates[0].content.parts[0].function_call:\n",
    "        function_calls.append(chunk.candidates[0].content.parts[0].function_call)\n",
    "    elif chunk.text:\n",
    "        print(chunk.text, end='', flush=True)\n",
    "\n",
    "# Handle any function calls\n",
    "if function_calls:\n",
    "    print(\"\\n\\n[Function call detected]\")\n",
    "    for fc in function_calls:\n",
    "        result = execute_function_call(fc)\n",
    "        print(f\"Result: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Advanced: Building a Calculator Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# Define calculator functions\n",
    "def calculate(operation: str, x: float, y: float = None) -> float:\n",
    "    \"\"\"Perform mathematical calculations.\"\"\"\n",
    "    operations = {\n",
    "        \"add\": lambda a, b: a + b,\n",
    "        \"subtract\": lambda a, b: a - b,\n",
    "        \"multiply\": lambda a, b: a * b,\n",
    "        \"divide\": lambda a, b: a / b if b != 0 else float('inf'),\n",
    "        \"power\": lambda a, b: a ** b,\n",
    "        \"sqrt\": lambda a, b: math.sqrt(a),\n",
    "        \"log\": lambda a, b: math.log(a)\n",
    "    }\n",
    "    \n",
    "    if operation in operations:\n",
    "        return operations[operation](x, y) if y is not None else operations[operation](x, 0)\n",
    "    return None\n",
    "\n",
    "# Define the function schema\n",
    "calc_function = genai.protos.FunctionDeclaration(\n",
    "    name=\"calculate\",\n",
    "    description=\"Perform mathematical calculations including add, subtract, multiply, divide, power, sqrt, log\",\n",
    "    parameters=genai.protos.Schema(\n",
    "        type=genai.protos.Type.OBJECT,\n",
    "        properties={\n",
    "            \"operation\": genai.protos.Schema(\n",
    "                type=genai.protos.Type.STRING,\n",
    "                description=\"The operation to perform\",\n",
    "                enum=[\"add\", \"subtract\", \"multiply\", \"divide\", \"power\", \"sqrt\", \"log\"]\n",
    "            ),\n",
    "            \"x\": genai.protos.Schema(\n",
    "                type=genai.protos.Type.NUMBER,\n",
    "                description=\"First number\"\n",
    "            ),\n",
    "            \"y\": genai.protos.Schema(\n",
    "                type=genai.protos.Type.NUMBER,\n",
    "                description=\"Second number (optional for unary operations)\"\n",
    "            )\n",
    "        },\n",
    "        required=[\"operation\", \"x\"]\n",
    "    )\n",
    ")\n",
    "\n",
    "calc_tool = genai.protos.Tool(function_declarations=[calc_function])\n",
    "calc_model = genai.GenerativeModel('gemini-3-pro', tools=[calc_tool])\n",
    "\n",
    "# Test the calculator\n",
    "questions = [\n",
    "    \"What is 15 plus 27?\",\n",
    "    \"What is the square root of 144?\",\n",
    "    \"Calculate 2 to the power of 8\"\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Q: {question}\")\n",
    "    \n",
    "    chat = calc_model.start_chat()\n",
    "    response = chat.send_message(question)\n",
    "    \n",
    "    if response.candidates[0].content.parts[0].function_call:\n",
    "        fc = response.candidates[0].content.parts[0].function_call\n",
    "        result = calculate(**dict(fc.args))\n",
    "        \n",
    "        response = chat.send_message(\n",
    "            genai.protos.Content(\n",
    "                parts=[genai.protos.Part(\n",
    "                    function_response=genai.protos.FunctionResponse(\n",
    "                        name=\"calculate\",\n",
    "                        response={\"result\": result}\n",
    "                    )\n",
    "                )]\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    print(f\"A: {response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Error Handling with Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_execute_function(function_call):\n",
    "    \"\"\"Safely execute a function call with error handling.\"\"\"\n",
    "    try:\n",
    "        function_name = function_call.name\n",
    "        function_args = dict(function_call.args)\n",
    "        \n",
    "        available_functions = {\n",
    "            \"calculate\": calculate,\n",
    "            \"get_weather\": get_weather,\n",
    "        }\n",
    "        \n",
    "        if function_name not in available_functions:\n",
    "            return {\"error\": f\"Function {function_name} not available\"}\n",
    "        \n",
    "        result = available_functions[function_name](**function_args)\n",
    "        return {\"success\": True, \"result\": result}\n",
    "        \n",
    "    except TypeError as e:\n",
    "        return {\"error\": f\"Invalid arguments: {str(e)}\"}\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Execution error: {str(e)}\"}\n",
    "\n",
    "# Test error handling\n",
    "print(\"Testing safe function execution...\\n\")\n",
    "\n",
    "# This will work\n",
    "test_call = genai.protos.FunctionCall(\n",
    "    name=\"calculate\",\n",
    "    args={\"operation\": \"add\", \"x\": 5, \"y\": 3}\n",
    ")\n",
    "print(f\"Valid call result: {safe_execute_function(test_call)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Now that you've mastered advanced features, explore:\n",
    "- Building RAG systems with ChromaDB\n",
    "- Creating autonomous agents with LangGraph\n",
    "- Developing interactive Streamlit applications\n",
    "\n",
    "---\n",
    "\n",
    "## Learn More\n",
    "\n",
    "Master advanced Generative AI techniques with the **[Gen AI Crash Course](https://www.buildfastwithai.com/genai-course)** by Build Fast with AI!\n",
    "\n",
    "**Created by [Build Fast with AI](https://www.buildfastwithai.com)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
