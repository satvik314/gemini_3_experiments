{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Streamlit Document Q&A Application\n",
    "\n",
    "> **Created by [Build Fast with AI](https://www.buildfastwithai.com)**\n",
    "\n",
    "This notebook demonstrates how to build a document question-answering application using Streamlit, Gemini 3 Pro, and RAG (Retrieval-Augmented Generation).\n",
    "\n",
    "## What you'll learn:\n",
    "- Building document upload interfaces\n",
    "- Extracting text from various file formats\n",
    "- Creating vector embeddings\n",
    "- Implementing RAG for Q&A\n",
    "- Building interactive document viewers\n",
    "- Managing document collections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## 1. Installation and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q streamlit google-generativeai chromadb langchain langchain-google-genai pypdf python-docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure API key\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
    "except:\n",
    "    GOOGLE_API_KEY = os.environ.get('GOOGLE_API_KEY', 'your-api-key-here')\n",
    "\n",
    "genai.configure(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## 2. Document Processing Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document processing functions\n",
    "from typing import List, Dict\n",
    "import re\n",
    "\n",
    "def extract_text_from_txt(file) -> str:\n",
    "    \"\"\"Extract text from TXT file.\"\"\"\n",
    "    return file.read().decode('utf-8')\n",
    "\n",
    "def extract_text_from_pdf(file) -> str:\n",
    "    \"\"\"Extract text from PDF file.\"\"\"\n",
    "    try:\n",
    "        from PyPDF2 import PdfReader\n",
    "        pdf = PdfReader(file)\n",
    "        text = \"\"\n",
    "        for page in pdf.pages:\n",
    "            text += page.extract_text()\n",
    "        return text\n",
    "    except ImportError:\n",
    "        return \"PyPDF2 not installed. Run: pip install pypdf\"\n",
    "\n",
    "def extract_text_from_docx(file) -> str:\n",
    "    \"\"\"Extract text from DOCX file.\"\"\"\n",
    "    try:\n",
    "        from docx import Document\n",
    "        doc = Document(file)\n",
    "        text = \"\\n\".join([paragraph.text for paragraph in doc.paragraphs])\n",
    "        return text\n",
    "    except ImportError:\n",
    "        return \"python-docx not installed. Run: pip install python-docx\"\n",
    "\n",
    "def chunk_text(text: str, chunk_size: int = 1000, overlap: int = 200) -> List[str]:\n",
    "    \"\"\"Split text into overlapping chunks.\"\"\"\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    \n",
    "    for i in range(0, len(words), chunk_size - overlap):\n",
    "        chunk = \" \".join(words[i:i + chunk_size])\n",
    "        chunks.append(chunk)\n",
    "        \n",
    "        if i + chunk_size >= len(words):\n",
    "            break\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "# Test document processing\n",
    "sample_text = \"\"\"Artificial Intelligence (AI) is transforming the world. \n",
    "Machine learning, a subset of AI, enables computers to learn from data. \n",
    "Deep learning uses neural networks with multiple layers to process complex patterns.\n",
    "Natural language processing helps computers understand human language.\n",
    "Computer vision enables machines to interpret visual information.\"\"\"\n",
    "\n",
    "chunks = chunk_text(sample_text, chunk_size=20, overlap=5)\n",
    "print(f\"Created {len(chunks)} chunks from sample text\\n\")\n",
    "for i, chunk in enumerate(chunks, 1):\n",
    "    print(f\"Chunk {i}: {chunk}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## 3. Basic Document Q&A System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDocumentQA:\n",
    "    \"\"\"Simple document Q&A without vector search.\"\"\"\n",
    "    \n",
    "    def __init__(self, document_text: str):\n",
    "        self.document = document_text\n",
    "        self.model = genai.GenerativeModel('gemini-3-pro')\n",
    "    \n",
    "    def ask(self, question: str) -> str:\n",
    "        \"\"\"Ask a question about the document.\"\"\"\n",
    "        prompt = f\"\"\"\n",
    "        Based on the following document, answer the question.\n",
    "        If the answer is not in the document, say \"I cannot find that information in the document.\"\n",
    "        \n",
    "        Document:\n",
    "        {self.document}\n",
    "        \n",
    "        Question: {question}\n",
    "        \n",
    "        Answer:\n",
    "        \"\"\"\n",
    "        \n",
    "        response = self.model.generate_content(prompt)\n",
    "        return response.text\n",
    "\n",
    "# Test with sample document\n",
    "doc_text = \"\"\"\n",
    "The Python programming language was created by Guido van Rossum and first released in 1991.\n",
    "Python is known for its simple, readable syntax and comprehensive standard library.\n",
    "It is widely used in web development, data science, artificial intelligence, and automation.\n",
    "Python 3.0 was released in 2008 and introduced several breaking changes from Python 2.\n",
    "The Python Software Foundation manages the development of Python.\n",
    "\"\"\"\n",
    "\n",
    "qa_system = SimpleDocumentQA(doc_text)\n",
    "\n",
    "questions = [\n",
    "    \"Who created Python?\",\n",
    "    \"When was Python first released?\",\n",
    "    \"What is Python used for?\",\n",
    "    \"What is the capital of France?\"  # Not in document\n",
    "]\n",
    "\n",
    "for q in questions:\n",
    "    print(f\"\\nQ: {q}\")\n",
    "    answer = qa_system.ask(q)\n",
    "    print(f\"A: {answer}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## 4. RAG-Based Document Q&A with ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "class RAGDocumentQA:\n",
    "    \"\"\"RAG-based document Q&A with vector search.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.client = chromadb.Client()\n",
    "        self.embedding_function = embedding_functions.DefaultEmbeddingFunction()\n",
    "        self.collection = self.client.create_collection(\n",
    "            name=\"documents\",\n",
    "            embedding_function=self.embedding_function\n",
    "        )\n",
    "        self.model = genai.GenerativeModel('gemini-3-pro')\n",
    "    \n",
    "    def add_document(self, text: str, doc_id: str, chunk_size: int = 500):\n",
    "        \"\"\"Add a document to the collection.\"\"\"\n",
    "        chunks = chunk_text(text, chunk_size=chunk_size)\n",
    "        \n",
    "        for i, chunk in enumerate(chunks):\n",
    "            self.collection.add(\n",
    "                documents=[chunk],\n",
    "                ids=[f\"{doc_id}_chunk_{i}\"],\n",
    "                metadatas=[{\"doc_id\": doc_id, \"chunk_index\": i}]\n",
    "            )\n",
    "        \n",
    "        return len(chunks)\n",
    "    \n",
    "    def ask(self, question: str, n_results: int = 3) -> Dict:\n",
    "        \"\"\"Ask a question and retrieve relevant context.\"\"\"\n",
    "        # Search for relevant chunks\n",
    "        results = self.collection.query(\n",
    "            query_texts=[question],\n",
    "            n_results=n_results\n",
    "        )\n",
    "        \n",
    "        # Combine relevant chunks\n",
    "        context = \"\\n\\n\".join(results['documents'][0])\n",
    "        \n",
    "        # Generate answer\n",
    "        prompt = f\"\"\"\n",
    "        Answer the question based on the following context.\n",
    "        If you cannot answer based on the context, say so.\n",
    "        \n",
    "        Context:\n",
    "        {context}\n",
    "        \n",
    "        Question: {question}\n",
    "        \n",
    "        Answer:\n",
    "        \"\"\"\n",
    "        \n",
    "        response = self.model.generate_content(prompt)\n",
    "        \n",
    "        return {\n",
    "            \"answer\": response.text,\n",
    "            \"context\": context,\n",
    "            \"sources\": results['metadatas'][0]\n",
    "        }\n",
    "\n",
    "# Test RAG system\n",
    "rag_qa = RAGDocumentQA()\n",
    "\n",
    "# Add multiple documents\n",
    "docs = {\n",
    "    \"python_intro\": \"\"\"Python is a high-level programming language created by Guido van Rossum.\n",
    "    It was first released in 1991 and emphasizes code readability. Python supports multiple\n",
    "    programming paradigms including procedural, object-oriented, and functional programming.\"\"\",\n",
    "    \n",
    "    \"python_applications\": \"\"\"Python is widely used in many domains. In web development,\n",
    "    frameworks like Django and Flask are popular. For data science, libraries like NumPy,\n",
    "    Pandas, and Scikit-learn are essential. Python is also the leading language for\n",
    "    artificial intelligence and machine learning with libraries like TensorFlow and PyTorch.\"\"\",\n",
    "    \n",
    "    \"python_features\": \"\"\"Python features include dynamic typing, automatic memory management,\n",
    "    and a comprehensive standard library. The language uses indentation for code blocks\n",
    "    instead of braces. Python's syntax is designed to be clean and easy to read.\"\"\"\n",
    "}\n",
    "\n",
    "for doc_id, text in docs.items():\n",
    "    chunks = rag_qa.add_document(text, doc_id)\n",
    "    print(f\"Added {doc_id}: {chunks} chunks\")\n",
    "\n",
    "# Ask questions\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "questions = [\n",
    "    \"What is Python used for in data science?\",\n",
    "    \"Who created Python?\",\n",
    "    \"What are Python's main features?\"\n",
    "]\n",
    "\n",
    "for q in questions:\n",
    "    print(f\"Question: {q}\\n\")\n",
    "    result = rag_qa.ask(q)\n",
    "    print(f\"Answer: {result['answer']}\\n\")\n",
    "    print(f\"Sources: {result['sources']}\")\n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## 5. Streamlit Document Q&A App - Basic Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save this as document_qa_basic.py\n",
    "basic_app_code = '''\n",
    "import streamlit as st\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "st.set_page_config(\n",
    "    page_title=\"Document Q&A\",\n",
    "    page_icon=\"üìÑ\",\n",
    "    layout=\"wide\"\n",
    ")\n",
    "\n",
    "st.title(\"üìÑ Document Question & Answer\")\n",
    "st.caption(\"Upload a document and ask questions about it\")\n",
    "\n",
    "# API Key\n",
    "api_key = os.environ.get('GOOGLE_API_KEY')\n",
    "if not api_key:\n",
    "    api_key = st.sidebar.text_input(\"Google API Key\", type=\"password\")\n",
    "\n",
    "if api_key:\n",
    "    genai.configure(api_key=api_key)\n",
    "    \n",
    "    # File upload\n",
    "    uploaded_file = st.file_uploader(\n",
    "        \"Upload a document (TXT, PDF, or DOCX)\",\n",
    "        type=[\"txt\", \"pdf\", \"docx\"]\n",
    "    )\n",
    "    \n",
    "    if uploaded_file:\n",
    "        # Extract text based on file type\n",
    "        if uploaded_file.type == \"text/plain\":\n",
    "            text = uploaded_file.read().decode(\"utf-8\")\n",
    "        elif uploaded_file.type == \"application/pdf\":\n",
    "            from PyPDF2 import PdfReader\n",
    "            pdf = PdfReader(uploaded_file)\n",
    "            text = \"\"\n",
    "            for page in pdf.pages:\n",
    "                text += page.extract_text()\n",
    "        elif uploaded_file.type == \"application/vnd.openxmlformats-officedocument.wordprocessingml.document\":\n",
    "            from docx import Document\n",
    "            doc = Document(uploaded_file)\n",
    "            text = \"\\n\".join([para.text for para in doc.paragraphs])\n",
    "        \n",
    "        # Store in session state\n",
    "        st.session_state.document_text = text\n",
    "        \n",
    "        # Display document info\n",
    "        col1, col2, col3 = st.columns(3)\n",
    "        with col1:\n",
    "            st.metric(\"Characters\", len(text))\n",
    "        with col2:\n",
    "            st.metric(\"Words\", len(text.split()))\n",
    "        with col3:\n",
    "            st.metric(\"Lines\", text.count(\"\\n\"))\n",
    "        \n",
    "        # Show document preview\n",
    "        with st.expander(\"üìñ Document Preview\"):\n",
    "            st.text_area(\"Content\", text[:2000] + \"...\" if len(text) > 2000 else text, height=300)\n",
    "        \n",
    "        st.divider()\n",
    "        \n",
    "        # Q&A interface\n",
    "        st.subheader(\"Ask Questions\")\n",
    "        \n",
    "        question = st.text_input(\"Enter your question:\")\n",
    "        \n",
    "        if st.button(\"Get Answer\", type=\"primary\"):\n",
    "            if question:\n",
    "                with st.spinner(\"Finding answer...\"):\n",
    "                    model = genai.GenerativeModel('gemini-3-pro')\n",
    "                    \n",
    "                    prompt = f\"\"\"\n",
    "                    Based on the following document, answer the question.\n",
    "                    If the answer is not in the document, say so clearly.\n",
    "                    \n",
    "                    Document:\n",
    "                    {text}\n",
    "                    \n",
    "                    Question: {question}\n",
    "                    \n",
    "                    Answer:\n",
    "                    \"\"\"\n",
    "                    \n",
    "                    response = model.generate_content(prompt)\n",
    "                    \n",
    "                    st.success(\"Answer:\")\n",
    "                    st.markdown(response.text)\n",
    "            else:\n",
    "                st.warning(\"Please enter a question\")\n",
    "    else:\n",
    "        st.info(\"üëÜ Upload a document to get started\")\n",
    "else:\n",
    "    st.warning(\"Please enter your API key in the sidebar\")\n",
    "'''\n",
    "\n",
    "with open('document_qa_basic.py', 'w') as f:\n",
    "    f.write(basic_app_code)\n",
    "\n",
    "print(\"Basic Document Q&A app saved to document_qa_basic.py\")\n",
    "print(\"\\nTo run: streamlit run document_qa_basic.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## 6. Advanced Document Q&A App with RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save this as document_qa_advanced.py\n",
    "advanced_app_code = '''\n",
    "import streamlit as st\n",
    "import google.generativeai as genai\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "import os\n",
    "from PyPDF2 import PdfReader\n",
    "from docx import Document\n",
    "\n",
    "st.set_page_config(\n",
    "    page_title=\"Advanced Document Q&A\",\n",
    "    page_icon=\"üîç\",\n",
    "    layout=\"wide\"\n",
    ")\n",
    "\n",
    "# Custom CSS\n",
    "st.markdown(\"\"\"\n",
    "<style>\n",
    "    .stApp {\n",
    "        max-width: 1200px;\n",
    "        margin: 0 auto;\n",
    "    }\n",
    "    .upload-section {\n",
    "        background-color: #f0f2f6;\n",
    "        padding: 2rem;\n",
    "        border-radius: 10px;\n",
    "        margin-bottom: 2rem;\n",
    "    }\n",
    "</style>\n",
    "\"\"\", unsafe_allow_html=True)\n",
    "\n",
    "st.title(\"üîç Advanced Document Q&A with RAG\")\n",
    "st.caption(\"Upload multiple documents and ask questions using semantic search\")\n",
    "\n",
    "# Sidebar configuration\n",
    "with st.sidebar:\n",
    "    st.header(\"‚öôÔ∏è Configuration\")\n",
    "    \n",
    "    api_key = os.environ.get('GOOGLE_API_KEY')\n",
    "    if not api_key:\n",
    "        api_key = st.text_input(\"Google API Key\", type=\"password\")\n",
    "    \n",
    "    st.divider()\n",
    "    \n",
    "    st.subheader(\"RAG Parameters\")\n",
    "    chunk_size = st.slider(\"Chunk Size\", 200, 1000, 500, 50)\n",
    "    n_results = st.slider(\"Results to Retrieve\", 1, 5, 3)\n",
    "    \n",
    "    st.divider()\n",
    "    \n",
    "    if st.button(\"üóëÔ∏è Clear All Documents\"):\n",
    "        if \"collection\" in st.session_state:\n",
    "            st.session_state.documents = {}\n",
    "            st.rerun()\n",
    "\n",
    "# Helper functions\n",
    "def chunk_text(text, chunk_size=500, overlap=100):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    for i in range(0, len(words), chunk_size - overlap):\n",
    "        chunk = \" \".join(words[i:i + chunk_size])\n",
    "        chunks.append(chunk)\n",
    "        if i + chunk_size >= len(words):\n",
    "            break\n",
    "    return chunks\n",
    "\n",
    "def extract_text(uploaded_file):\n",
    "    if uploaded_file.type == \"text/plain\":\n",
    "        return uploaded_file.read().decode(\"utf-8\")\n",
    "    elif uploaded_file.type == \"application/pdf\":\n",
    "        pdf = PdfReader(uploaded_file)\n",
    "        return \"\".join([page.extract_text() for page in pdf.pages])\n",
    "    elif uploaded_file.type == \"application/vnd.openxmlformats-officedocument.wordprocessingml.document\":\n",
    "        doc = Document(uploaded_file)\n",
    "        return \"\\n\".join([para.text for para in doc.paragraphs])\n",
    "    return \"\"\n",
    "\n",
    "if api_key:\n",
    "    genai.configure(api_key=api_key)\n",
    "    \n",
    "    # Initialize ChromaDB\n",
    "    if \"collection\" not in st.session_state:\n",
    "        client = chromadb.Client()\n",
    "        embedding_function = embedding_functions.DefaultEmbeddingFunction()\n",
    "        st.session_state.collection = client.create_collection(\n",
    "            name=\"documents\",\n",
    "            embedding_function=embedding_function\n",
    "        )\n",
    "        st.session_state.documents = {}\n",
    "    \n",
    "    # Document upload section\n",
    "    st.subheader(\"üì§ Upload Documents\")\n",
    "    \n",
    "    uploaded_files = st.file_uploader(\n",
    "        \"Choose files\",\n",
    "        type=[\"txt\", \"pdf\", \"docx\"],\n",
    "        accept_multiple_files=True\n",
    "    )\n",
    "    \n",
    "    if uploaded_files:\n",
    "        for uploaded_file in uploaded_files:\n",
    "            doc_id = uploaded_file.name\n",
    "            \n",
    "            if doc_id not in st.session_state.documents:\n",
    "                with st.spinner(f\"Processing {doc_id}...\"):\n",
    "                    text = extract_text(uploaded_file)\n",
    "                    chunks = chunk_text(text, chunk_size=chunk_size)\n",
    "                    \n",
    "                    # Add to ChromaDB\n",
    "                    for i, chunk in enumerate(chunks):\n",
    "                        st.session_state.collection.add(\n",
    "                            documents=[chunk],\n",
    "                            ids=[f\"{doc_id}_chunk_{i}\"],\n",
    "                            metadatas=[{\"doc_id\": doc_id, \"chunk_index\": i}]\n",
    "                        )\n",
    "                    \n",
    "                    st.session_state.documents[doc_id] = {\n",
    "                        \"text\": text,\n",
    "                        \"chunks\": len(chunks)\n",
    "                    }\n",
    "                    \n",
    "                    st.success(f\"‚úÖ {doc_id} processed ({len(chunks)} chunks)\")\n",
    "    \n",
    "    # Display loaded documents\n",
    "    if st.session_state.documents:\n",
    "        st.divider()\n",
    "        st.subheader(\"üìö Loaded Documents\")\n",
    "        \n",
    "        for doc_id, info in st.session_state.documents.items():\n",
    "            with st.expander(f\"üìÑ {doc_id}\"):\n",
    "                col1, col2 = st.columns(2)\n",
    "                with col1:\n",
    "                    st.metric(\"Chunks\", info[\"chunks\"])\n",
    "                with col2:\n",
    "                    st.metric(\"Characters\", len(info[\"text\"]))\n",
    "                \n",
    "                st.text_area(\n",
    "                    \"Preview\",\n",
    "                    info[\"text\"][:500] + \"...\" if len(info[\"text\"]) > 500 else info[\"text\"],\n",
    "                    height=100,\n",
    "                    key=f\"preview_{doc_id}\"\n",
    "                )\n",
    "        \n",
    "        st.divider()\n",
    "        \n",
    "        # Q&A Interface\n",
    "        st.subheader(\"üí¨ Ask Questions\")\n",
    "        \n",
    "        # Initialize chat history\n",
    "        if \"qa_history\" not in st.session_state:\n",
    "            st.session_state.qa_history = []\n",
    "        \n",
    "        # Display chat history\n",
    "        for qa in st.session_state.qa_history:\n",
    "            with st.chat_message(\"user\"):\n",
    "                st.write(qa[\"question\"])\n",
    "            with st.chat_message(\"assistant\"):\n",
    "                st.write(qa[\"answer\"])\n",
    "                if qa.get(\"sources\"):\n",
    "                    st.caption(f\"üìé Sources: {', '.join(set([s['doc_id'] for s in qa['sources']]))}\")\n",
    "        \n",
    "        # Question input\n",
    "        question = st.chat_input(\"Ask a question about your documents...\")\n",
    "        \n",
    "        if question:\n",
    "            with st.chat_message(\"user\"):\n",
    "                st.write(question)\n",
    "            \n",
    "            with st.chat_message(\"assistant\"):\n",
    "                with st.spinner(\"Searching and generating answer...\"):\n",
    "                    # Search for relevant chunks\n",
    "                    results = st.session_state.collection.query(\n",
    "                        query_texts=[question],\n",
    "                        n_results=n_results\n",
    "                    )\n",
    "                    \n",
    "                    context = \"\\n\\n\".join(results['documents'][0])\n",
    "                    sources = results['metadatas'][0]\n",
    "                    \n",
    "                    # Generate answer\n",
    "                    model = genai.GenerativeModel('gemini-3-pro')\n",
    "                    prompt = f\"\"\"\n",
    "                    Answer the question based on the following context from uploaded documents.\n",
    "                    Be specific and cite relevant information from the context.\n",
    "                    If the answer is not in the context, say so.\n",
    "                    \n",
    "                    Context:\n",
    "                    {context}\n",
    "                    \n",
    "                    Question: {question}\n",
    "                    \n",
    "                    Answer:\n",
    "                    \"\"\"\n",
    "                    \n",
    "                    response = model.generate_content(prompt)\n",
    "                    answer = response.text\n",
    "                    \n",
    "                    st.write(answer)\n",
    "                    \n",
    "                    # Show sources\n",
    "                    unique_docs = set([s['doc_id'] for s in sources])\n",
    "                    st.caption(f\"üìé Sources: {', '.join(unique_docs)}\")\n",
    "                    \n",
    "                    # Save to history\n",
    "                    st.session_state.qa_history.append({\n",
    "                        \"question\": question,\n",
    "                        \"answer\": answer,\n",
    "                        \"sources\": sources\n",
    "                    })\n",
    "    else:\n",
    "        st.info(\"üëÜ Upload documents to start asking questions\")\n",
    "else:\n",
    "    st.warning(\"Please enter your API key in the sidebar\")\n",
    "'''\n",
    "\n",
    "with open('document_qa_advanced.py', 'w') as f:\n",
    "    f.write(advanced_app_code)\n",
    "\n",
    "print(\"Advanced Document Q&A app saved to document_qa_advanced.py\")\n",
    "print(\"\\nTo run: streamlit run document_qa_advanced.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## 7. Document Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentSummarizer:\n",
    "    \"\"\"Summarize documents using Gemini.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = genai.GenerativeModel('gemini-3-pro')\n",
    "    \n",
    "    def summarize(self, text: str, style: str = \"concise\") -> str:\n",
    "        \"\"\"Summarize text in different styles.\"\"\"\n",
    "        style_prompts = {\n",
    "            \"concise\": \"Provide a brief, concise summary in 2-3 sentences.\",\n",
    "            \"detailed\": \"Provide a detailed summary covering all main points.\",\n",
    "            \"bullet\": \"Provide a summary as bullet points of key information.\",\n",
    "            \"executive\": \"Provide an executive summary for business stakeholders.\"\n",
    "        }\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        {style_prompts.get(style, style_prompts[\"concise\"])}\n",
    "        \n",
    "        Document:\n",
    "        {text}\n",
    "        \n",
    "        Summary:\n",
    "        \"\"\"\n",
    "        \n",
    "        response = self.model.generate_content(prompt)\n",
    "        return response.text\n",
    "    \n",
    "    def extract_key_points(self, text: str, n_points: int = 5) -> str:\n",
    "        \"\"\"Extract key points from document.\"\"\"\n",
    "        prompt = f\"\"\"\n",
    "        Extract the {n_points} most important key points from this document.\n",
    "        Format as a numbered list.\n",
    "        \n",
    "        Document:\n",
    "        {text}\n",
    "        \n",
    "        Key Points:\n",
    "        \"\"\"\n",
    "        \n",
    "        response = self.model.generate_content(prompt)\n",
    "        return response.text\n",
    "\n",
    "# Test summarization\n",
    "long_doc = \"\"\"\n",
    "Machine learning is a subset of artificial intelligence that enables computers to learn \n",
    "from data without being explicitly programmed. The field has evolved significantly over \n",
    "the past decades, with deep learning emerging as a powerful technique for handling \n",
    "complex patterns in large datasets.\n",
    "\n",
    "Supervised learning involves training models on labeled data, where the correct output \n",
    "is known. Common algorithms include linear regression, decision trees, and neural networks. \n",
    "These methods are widely used in applications like image classification, speech recognition, \n",
    "and predictive analytics.\n",
    "\n",
    "Unsupervised learning, on the other hand, works with unlabeled data to discover hidden \n",
    "patterns. Clustering algorithms like K-means and dimensionality reduction techniques like \n",
    "PCA are popular unsupervised learning methods. These are useful for exploratory data \n",
    "analysis and feature engineering.\n",
    "\n",
    "Reinforcement learning is a third paradigm where agents learn through trial and error, \n",
    "receiving rewards or penalties for their actions. This approach has achieved remarkable \n",
    "success in game playing, robotics, and autonomous systems.\n",
    "\"\"\"\n",
    "\n",
    "summarizer = DocumentSummarizer()\n",
    "\n",
    "print(\"ORIGINAL DOCUMENT:\")\n",
    "print(\"=\" * 80)\n",
    "print(long_doc)\n",
    "\n",
    "print(\"\\n\\nCONCISE SUMMARY:\")\n",
    "print(\"=\" * 80)\n",
    "print(summarizer.summarize(long_doc, style=\"concise\"))\n",
    "\n",
    "print(\"\\n\\nBULLET POINT SUMMARY:\")\n",
    "print(\"=\" * 80)\n",
    "print(summarizer.summarize(long_doc, style=\"bullet\"))\n",
    "\n",
    "print(\"\\n\\nKEY POINTS:\")\n",
    "print(\"=\" * 80)\n",
    "print(summarizer.extract_key_points(long_doc, n_points=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "## 8. Document Comparison Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentComparer:\n",
    "    \"\"\"Compare multiple documents.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = genai.GenerativeModel('gemini-3-pro')\n",
    "    \n",
    "    def compare(self, doc1: str, doc2: str) -> str:\n",
    "        \"\"\"Compare two documents.\"\"\"\n",
    "        prompt = f\"\"\"\n",
    "        Compare these two documents and provide:\n",
    "        1. Main similarities\n",
    "        2. Key differences\n",
    "        3. Unique points in each document\n",
    "        \n",
    "        Document 1:\n",
    "        {doc1}\n",
    "        \n",
    "        Document 2:\n",
    "        {doc2}\n",
    "        \n",
    "        Comparison:\n",
    "        \"\"\"\n",
    "        \n",
    "        response = self.model.generate_content(prompt)\n",
    "        return response.text\n",
    "\n",
    "# Test comparison\n",
    "doc1 = \"Python is a high-level programming language known for its simplicity and readability. It's widely used in web development, data science, and automation.\"\n",
    "doc2 = \"JavaScript is a programming language primarily used for web development. It runs in browsers and enables interactive web pages. Node.js allows JavaScript to run on servers.\"\n",
    "\n",
    "comparer = DocumentComparer()\n",
    "comparison = comparer.compare(doc1, doc2)\n",
    "\n",
    "print(\"DOCUMENT COMPARISON:\")\n",
    "print(\"=\" * 80)\n",
    "display(Markdown(comparison))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "## 9. Running the Streamlit Apps\n",
    "\n",
    "### From Jupyter/Colab:\n",
    "\n",
    "```python\n",
    "# Method 1: Using subprocess (for local)\n",
    "import subprocess\n",
    "subprocess.Popen([\"streamlit\", \"run\", \"document_qa_basic.py\"])\n",
    "```\n",
    "\n",
    "### From Terminal:\n",
    "\n",
    "```bash\n",
    "# Basic version\n",
    "streamlit run document_qa_basic.py\n",
    "\n",
    "# Advanced version\n",
    "streamlit run document_qa_advanced.py\n",
    "```\n",
    "\n",
    "### From Colab with ngrok:\n",
    "\n",
    "```python\n",
    "!pip install pyngrok\n",
    "from pyngrok import ngrok\n",
    "\n",
    "# Set auth token\n",
    "ngrok.set_auth_token(\"YOUR_TOKEN\")\n",
    "\n",
    "# Start streamlit\n",
    "!streamlit run document_qa_advanced.py --server.port 8501 &\n",
    "\n",
    "# Create tunnel\n",
    "public_url = ngrok.connect(8501)\n",
    "print(public_url)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "## 10. Best Practices for Document Q&A Systems\n",
    "\n",
    "### Performance Optimization:\n",
    "\n",
    "1. **Chunking Strategy**: Balance chunk size for context vs. precision\n",
    "2. **Overlap**: Use overlapping chunks to preserve context\n",
    "3. **Embeddings**: Cache embeddings to avoid recomputation\n",
    "4. **Batch Processing**: Process multiple documents in parallel\n",
    "\n",
    "### Accuracy Improvements:\n",
    "\n",
    "1. **Metadata**: Add document metadata for better filtering\n",
    "2. **Reranking**: Rerank retrieved chunks before answering\n",
    "3. **Citation**: Always cite sources in answers\n",
    "4. **Validation**: Verify answers against source material\n",
    "\n",
    "### User Experience:\n",
    "\n",
    "1. **Preview**: Show document previews before processing\n",
    "2. **Progress**: Display processing progress for large files\n",
    "3. **Suggestions**: Offer sample questions\n",
    "4. **Export**: Allow exporting Q&A history\n",
    "\n",
    "### Production Considerations:\n",
    "\n",
    "1. **File Validation**: Validate file types and sizes\n",
    "2. **Error Handling**: Handle corrupt or unsupported files\n",
    "3. **Rate Limiting**: Implement API rate limiting\n",
    "4. **Persistence**: Store embeddings in persistent vector DB\n",
    "5. **Security**: Sanitize inputs and manage access control"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Expand your document Q&A capabilities:\n",
    "- Add support for more file formats (CSV, Excel, Markdown)\n",
    "- Implement document clustering and categorization\n",
    "- Build custom document collections\n",
    "- Add export to various formats\n",
    "- Integrate with cloud storage (Google Drive, Dropbox)\n",
    "\n",
    "---\n",
    "\n",
    "## Learn More\n",
    "\n",
    "Build powerful document processing systems with the **[Gen AI Crash Course](https://www.buildfastwithai.com/genai-course)** by Build Fast with AI!\n",
    "\n",
    "**Created by [Build Fast with AI](https://www.buildfastwithai.com)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
