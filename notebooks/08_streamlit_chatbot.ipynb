{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Streamlit Chatbot Application with Gemini 3 Pro\n",
    "\n",
    "> **Created by [Build Fast with AI](https://www.buildfastwithai.com)**\n",
    "\n",
    "This notebook shows you how to build an interactive chatbot application using Streamlit and Gemini 3 Pro.\n",
    "\n",
    "## What you'll learn:\n",
    "- Building Streamlit applications\n",
    "- Creating chatbot interfaces\n",
    "- Managing conversation history\n",
    "- Implementing session state\n",
    "- Customizing chat UI\n",
    "- Deploying chatbots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## 1. Installation and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q streamlit google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure API key\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
    "except:\n",
    "    GOOGLE_API_KEY = os.environ.get('GOOGLE_API_KEY', 'your-api-key-here')\n",
    "\n",
    "genai.configure(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## 2. Basic Streamlit Chatbot Code\n",
    "\n",
    "Let's create a simple chatbot application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save this as chatbot_basic.py\n",
    "basic_chatbot_code = '''\n",
    "import streamlit as st\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "# Configure page\n",
    "st.set_page_config(\n",
    "    page_title=\"Gemini Chatbot\",\n",
    "    page_icon=\"ðŸ¤–\",\n",
    "    layout=\"centered\"\n",
    ")\n",
    "\n",
    "# Title\n",
    "st.title(\"ðŸ¤– Gemini 3 Pro Chatbot\")\n",
    "st.caption(\"Built with Streamlit and Gemini 3 Pro\")\n",
    "\n",
    "# Get API key from environment or sidebar\n",
    "api_key = os.environ.get('GOOGLE_API_KEY')\n",
    "if not api_key:\n",
    "    api_key = st.sidebar.text_input(\"Enter Google API Key\", type=\"password\")\n",
    "\n",
    "if api_key:\n",
    "    genai.configure(api_key=api_key)\n",
    "    \n",
    "    # Initialize session state for messages\n",
    "    if \"messages\" not in st.session_state:\n",
    "        st.session_state.messages = []\n",
    "    \n",
    "    if \"chat\" not in st.session_state:\n",
    "        model = genai.GenerativeModel('gemini-3-pro')\n",
    "        st.session_state.chat = model.start_chat(history=[])\n",
    "    \n",
    "    # Display chat history\n",
    "    for message in st.session_state.messages:\n",
    "        with st.chat_message(message[\"role\"]):\n",
    "            st.markdown(message[\"content\"])\n",
    "    \n",
    "    # Chat input\n",
    "    if prompt := st.chat_input(\"What would you like to know?\"):\n",
    "        # Add user message to history\n",
    "        st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "        \n",
    "        # Display user message\n",
    "        with st.chat_message(\"user\"):\n",
    "            st.markdown(prompt)\n",
    "        \n",
    "        # Get bot response\n",
    "        with st.chat_message(\"assistant\"):\n",
    "            with st.spinner(\"Thinking...\"):\n",
    "                response = st.session_state.chat.send_message(prompt)\n",
    "                st.markdown(response.text)\n",
    "        \n",
    "        # Add assistant response to history\n",
    "        st.session_state.messages.append({\"role\": \"assistant\", \"content\": response.text})\n",
    "    \n",
    "    # Sidebar controls\n",
    "    with st.sidebar:\n",
    "        st.header(\"Controls\")\n",
    "        if st.button(\"Clear Chat History\"):\n",
    "            st.session_state.messages = []\n",
    "            model = genai.GenerativeModel('gemini-3-pro')\n",
    "            st.session_state.chat = model.start_chat(history=[])\n",
    "            st.rerun()\n",
    "else:\n",
    "    st.warning(\"Please enter your Google API key to start chatting.\")\n",
    "'''\n",
    "\n",
    "# Write to file\n",
    "with open('chatbot_basic.py', 'w') as f:\n",
    "    f.write(basic_chatbot_code)\n",
    "\n",
    "print(\"Basic chatbot code saved to chatbot_basic.py\")\n",
    "print(\"\\nTo run: streamlit run chatbot_basic.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## 3. Advanced Chatbot with System Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save this as chatbot_advanced.py\n",
    "advanced_chatbot_code = '''\n",
    "import streamlit as st\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "# Page config\n",
    "st.set_page_config(\n",
    "    page_title=\"Advanced Gemini Chatbot\",\n",
    "    page_icon=\"ðŸ¤–\",\n",
    "    layout=\"wide\"\n",
    ")\n",
    "\n",
    "# Custom CSS\n",
    "st.markdown(\"\"\"\n",
    "<style>\n",
    "    .stChatMessage {\n",
    "        padding: 1rem;\n",
    "        border-radius: 0.5rem;\n",
    "    }\n",
    "    .main-header {\n",
    "        font-size: 2.5rem;\n",
    "        font-weight: bold;\n",
    "        color: #1f77b4;\n",
    "        text-align: center;\n",
    "        margin-bottom: 1rem;\n",
    "    }\n",
    "</style>\n",
    "\"\"\", unsafe_allow_html=True)\n",
    "\n",
    "# Header\n",
    "st.markdown('<p class=\"main-header\">ðŸ¤– Advanced Gemini Chatbot</p>', unsafe_allow_html=True)\n",
    "st.caption(\"Customizable AI Assistant powered by Gemini 3 Pro\")\n",
    "\n",
    "# Sidebar configuration\n",
    "with st.sidebar:\n",
    "    st.header(\"âš™ï¸ Configuration\")\n",
    "    \n",
    "    # API Key\n",
    "    api_key = os.environ.get('GOOGLE_API_KEY')\n",
    "    if not api_key:\n",
    "        api_key = st.text_input(\"Google API Key\", type=\"password\")\n",
    "    \n",
    "    # Bot personality\n",
    "    st.subheader(\"Bot Personality\")\n",
    "    personality = st.selectbox(\n",
    "        \"Choose personality\",\n",
    "        [\"Professional Assistant\", \"Friendly Helper\", \"Technical Expert\", \"Creative Writer\", \"Custom\"]\n",
    "    )\n",
    "    \n",
    "    if personality == \"Custom\":\n",
    "        system_instruction = st.text_area(\n",
    "            \"Custom System Instruction\",\n",
    "            \"You are a helpful assistant.\"\n",
    "        )\n",
    "    else:\n",
    "        personality_prompts = {\n",
    "            \"Professional Assistant\": \"You are a professional assistant. Be concise, accurate, and helpful.\",\n",
    "            \"Friendly Helper\": \"You are a friendly and enthusiastic helper. Be warm, encouraging, and supportive.\",\n",
    "            \"Technical Expert\": \"You are a technical expert. Provide detailed, accurate technical information with code examples.\",\n",
    "            \"Creative Writer\": \"You are a creative writer. Be imaginative, expressive, and artistic in your responses.\"\n",
    "        }\n",
    "        system_instruction = personality_prompts[personality]\n",
    "    \n",
    "    # Model parameters\n",
    "    st.subheader(\"Model Parameters\")\n",
    "    temperature = st.slider(\"Temperature\", 0.0, 1.0, 0.7, 0.1)\n",
    "    max_tokens = st.slider(\"Max Output Tokens\", 256, 2048, 1024, 128)\n",
    "    \n",
    "    # Controls\n",
    "    st.subheader(\"Controls\")\n",
    "    if st.button(\"ðŸ—‘ï¸ Clear Chat\", use_container_width=True):\n",
    "        st.session_state.messages = []\n",
    "        st.session_state.chat = None\n",
    "        st.rerun()\n",
    "    \n",
    "    if st.button(\"ðŸ“¥ Export Chat\", use_container_width=True):\n",
    "        if \"messages\" in st.session_state and st.session_state.messages:\n",
    "            chat_text = \"\\n\\n\".join([\n",
    "                f\"{msg['role'].upper()}: {msg['content']}\"\n",
    "                for msg in st.session_state.messages\n",
    "            ])\n",
    "            st.download_button(\n",
    "                \"Download Chat\",\n",
    "                chat_text,\n",
    "                \"chat_history.txt\",\n",
    "                \"text/plain\",\n",
    "                use_container_width=True\n",
    "            )\n",
    "\n",
    "# Main chat interface\n",
    "if api_key:\n",
    "    genai.configure(api_key=api_key)\n",
    "    \n",
    "    # Initialize session state\n",
    "    if \"messages\" not in st.session_state:\n",
    "        st.session_state.messages = []\n",
    "    \n",
    "    # Initialize or update chat with current settings\n",
    "    if \"chat\" not in st.session_state or \"last_config\" not in st.session_state or \\\n",
    "       st.session_state.last_config != (system_instruction, temperature, max_tokens):\n",
    "        \n",
    "        generation_config = {\n",
    "            \"temperature\": temperature,\n",
    "            \"max_output_tokens\": max_tokens,\n",
    "        }\n",
    "        \n",
    "        model = genai.GenerativeModel(\n",
    "            'gemini-3-pro',\n",
    "            generation_config=generation_config,\n",
    "            system_instruction=system_instruction\n",
    "        )\n",
    "        st.session_state.chat = model.start_chat(history=[])\n",
    "        st.session_state.last_config = (system_instruction, temperature, max_tokens)\n",
    "    \n",
    "    # Display chat history\n",
    "    for message in st.session_state.messages:\n",
    "        with st.chat_message(message[\"role\"]):\n",
    "            st.markdown(message[\"content\"])\n",
    "    \n",
    "    # Chat input\n",
    "    if prompt := st.chat_input(\"Ask me anything...\"):\n",
    "        # Add user message\n",
    "        st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "        \n",
    "        with st.chat_message(\"user\"):\n",
    "            st.markdown(prompt)\n",
    "        \n",
    "        # Get and display assistant response\n",
    "        with st.chat_message(\"assistant\"):\n",
    "            with st.spinner(\"âœ¨ Thinking...\"):\n",
    "                try:\n",
    "                    response = st.session_state.chat.send_message(prompt)\n",
    "                    st.markdown(response.text)\n",
    "                    st.session_state.messages.append({\"role\": \"assistant\", \"content\": response.text})\n",
    "                except Exception as e:\n",
    "                    error_msg = f\"Error: {str(e)}\"\n",
    "                    st.error(error_msg)\n",
    "                    st.session_state.messages.append({\"role\": \"assistant\", \"content\": error_msg})\n",
    "    \n",
    "    # Show message count in sidebar\n",
    "    with st.sidebar:\n",
    "        st.divider()\n",
    "        st.caption(f\"ðŸ’¬ Messages: {len(st.session_state.messages)}\")\n",
    "else:\n",
    "    st.info(\"ðŸ‘ˆ Please enter your Google API key in the sidebar to start chatting.\")\n",
    "    \n",
    "    st.markdown(\"\"\"\n",
    "    ### Features:\n",
    "    - ðŸŽ­ Multiple bot personalities\n",
    "    - âš™ï¸ Adjustable model parameters\n",
    "    - ðŸ’¾ Export chat history\n",
    "    - ðŸŽ¨ Custom UI styling\n",
    "    - ðŸ”„ Real-time configuration updates\n",
    "    \"\"\")\n",
    "'''\n",
    "\n",
    "with open('chatbot_advanced.py', 'w') as f:\n",
    "    f.write(advanced_chatbot_code)\n",
    "\n",
    "print(\"Advanced chatbot code saved to chatbot_advanced.py\")\n",
    "print(\"\\nTo run: streamlit run chatbot_advanced.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## 4. Chatbot with Memory Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Managing conversation memory in a notebook\n",
    "class ChatbotWithMemory:\n",
    "    \"\"\"Chatbot that manages conversation history.\"\"\"\n",
    "    \n",
    "    def __init__(self, max_history: int = 10):\n",
    "        self.max_history = max_history\n",
    "        self.model = genai.GenerativeModel('gemini-3-pro')\n",
    "        self.chat = self.model.start_chat(history=[])\n",
    "        self.full_history = []\n",
    "    \n",
    "    def send_message(self, message: str) -> str:\n",
    "        \"\"\"Send a message and get response.\"\"\"\n",
    "        # Get response\n",
    "        response = self.chat.send_message(message)\n",
    "        \n",
    "        # Store in full history\n",
    "        self.full_history.append({\n",
    "            \"role\": \"user\",\n",
    "            \"content\": message\n",
    "        })\n",
    "        self.full_history.append({\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": response.text\n",
    "        })\n",
    "        \n",
    "        # Trim history if needed\n",
    "        if len(self.full_history) > self.max_history * 2:\n",
    "            self.full_history = self.full_history[-(self.max_history * 2):]\n",
    "        \n",
    "        return response.text\n",
    "    \n",
    "    def get_history(self):\n",
    "        \"\"\"Get conversation history.\"\"\"\n",
    "        return self.full_history\n",
    "    \n",
    "    def clear_history(self):\n",
    "        \"\"\"Clear conversation history.\"\"\"\n",
    "        self.chat = self.model.start_chat(history=[])\n",
    "        self.full_history = []\n",
    "\n",
    "# Test the chatbot\n",
    "chatbot = ChatbotWithMemory(max_history=5)\n",
    "\n",
    "# Have a conversation\n",
    "messages = [\n",
    "    \"Hello! What's your name?\",\n",
    "    \"Can you explain what Python is?\",\n",
    "    \"What did I just ask you about?\"\n",
    "]\n",
    "\n",
    "for msg in messages:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"User: {msg}\")\n",
    "    response = chatbot.send_message(msg)\n",
    "    print(f\"\\nAssistant: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## 5. Running Streamlit Apps from Colab/Jupyter\n",
    "\n",
    "### Method 1: Using pyngrok (Recommended for Colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install pyngrok for tunneling\n",
    "!pip install -q pyngrok\n",
    "\n",
    "# Note: You'll need to sign up for a free ngrok account and get your auth token\n",
    "# Then run this code:\n",
    "\n",
    "ngrok_tunnel_code = '''\n",
    "from pyngrok import ngrok\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "# Set your ngrok auth token (get it from https://dashboard.ngrok.com/get-started/your-authtoken)\n",
    "# ngrok.set_auth_token(\"YOUR_NGROK_AUTH_TOKEN\")\n",
    "\n",
    "# Start streamlit in background\n",
    "streamlit_process = subprocess.Popen(\n",
    "    [\"streamlit\", \"run\", \"chatbot_basic.py\", \"--server.port\", \"8501\"],\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.PIPE\n",
    ")\n",
    "\n",
    "# Wait for streamlit to start\n",
    "time.sleep(5)\n",
    "\n",
    "# Create ngrok tunnel\n",
    "public_url = ngrok.connect(8501)\n",
    "print(f\"\\nâœ… Streamlit app is running at: {public_url}\")\n",
    "print(f\"\\nClick the link above to access your chatbot!\")\n",
    "'''\n",
    "\n",
    "print(\"To run Streamlit app from Colab:\")\n",
    "print(ngrok_tunnel_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "### Method 2: Local Development\n",
    "\n",
    "For local Jupyter notebooks, simply run:\n",
    "\n",
    "```bash\n",
    "# In terminal\n",
    "streamlit run chatbot_basic.py\n",
    "```\n",
    "\n",
    "The app will open automatically in your browser at `http://localhost:8501`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## 6. Chatbot with Streaming Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save this as chatbot_streaming.py\n",
    "streaming_chatbot_code = '''\n",
    "import streamlit as st\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "st.set_page_config(\n",
    "    page_title=\"Streaming Chatbot\",\n",
    "    page_icon=\"ðŸ’¬\",\n",
    "    layout=\"centered\"\n",
    ")\n",
    "\n",
    "st.title(\"ðŸ’¬ Streaming Chatbot\")\n",
    "st.caption(\"Watch responses appear in real-time!\")\n",
    "\n",
    "# API key\n",
    "api_key = os.environ.get('GOOGLE_API_KEY')\n",
    "if not api_key:\n",
    "    api_key = st.sidebar.text_input(\"Google API Key\", type=\"password\")\n",
    "\n",
    "if api_key:\n",
    "    genai.configure(api_key=api_key)\n",
    "    \n",
    "    # Initialize session state\n",
    "    if \"messages\" not in st.session_state:\n",
    "        st.session_state.messages = []\n",
    "    \n",
    "    if \"model\" not in st.session_state:\n",
    "        st.session_state.model = genai.GenerativeModel('gemini-3-pro')\n",
    "        st.session_state.chat = st.session_state.model.start_chat(history=[])\n",
    "    \n",
    "    # Display messages\n",
    "    for message in st.session_state.messages:\n",
    "        with st.chat_message(message[\"role\"]):\n",
    "            st.markdown(message[\"content\"])\n",
    "    \n",
    "    # Chat input\n",
    "    if prompt := st.chat_input(\"Your message...\"):\n",
    "        # Display user message\n",
    "        st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "        with st.chat_message(\"user\"):\n",
    "            st.markdown(prompt)\n",
    "        \n",
    "        # Stream assistant response\n",
    "        with st.chat_message(\"assistant\"):\n",
    "            message_placeholder = st.empty()\n",
    "            full_response = \"\"\n",
    "            \n",
    "            # Stream the response\n",
    "            for chunk in st.session_state.chat.send_message(prompt, stream=True):\n",
    "                full_response += chunk.text\n",
    "                message_placeholder.markdown(full_response + \"â–Œ\")\n",
    "            \n",
    "            message_placeholder.markdown(full_response)\n",
    "        \n",
    "        st.session_state.messages.append({\"role\": \"assistant\", \"content\": full_response})\n",
    "    \n",
    "    # Sidebar\n",
    "    with st.sidebar:\n",
    "        st.header(\"Controls\")\n",
    "        if st.button(\"Clear Chat\"):\n",
    "            st.session_state.messages = []\n",
    "            st.session_state.chat = st.session_state.model.start_chat(history=[])\n",
    "            st.rerun()\n",
    "else:\n",
    "    st.warning(\"Please enter your API key to start.\")\n",
    "'''\n",
    "\n",
    "with open('chatbot_streaming.py', 'w') as f:\n",
    "    f.write(streaming_chatbot_code)\n",
    "\n",
    "print(\"Streaming chatbot saved to chatbot_streaming.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## 7. Multi-Language Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chatbot that can converse in multiple languages\n",
    "class MultiLanguageChatbot:\n",
    "    \"\"\"Chatbot with multi-language support.\"\"\"\n",
    "    \n",
    "    def __init__(self, language: str = \"English\"):\n",
    "        self.language = language\n",
    "        self.system_instruction = f\"You are a helpful assistant. Always respond in {language}.\"\n",
    "        self.model = genai.GenerativeModel(\n",
    "            'gemini-3-pro',\n",
    "            system_instruction=self.system_instruction\n",
    "        )\n",
    "        self.chat = self.model.start_chat(history=[])\n",
    "    \n",
    "    def change_language(self, language: str):\n",
    "        \"\"\"Change the conversation language.\"\"\"\n",
    "        self.language = language\n",
    "        self.system_instruction = f\"You are a helpful assistant. Always respond in {language}.\"\n",
    "        self.model = genai.GenerativeModel(\n",
    "            'gemini-3-pro',\n",
    "            system_instruction=self.system_instruction\n",
    "        )\n",
    "        self.chat = self.model.start_chat(history=[])\n",
    "    \n",
    "    def send_message(self, message: str) -> str:\n",
    "        \"\"\"Send message and get response.\"\"\"\n",
    "        response = self.chat.send_message(message)\n",
    "        return response.text\n",
    "\n",
    "# Test with different languages\n",
    "languages = [\"English\", \"Spanish\", \"French\", \"German\"]\n",
    "question = \"What is artificial intelligence?\"\n",
    "\n",
    "for lang in languages:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Language: {lang}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    bot = MultiLanguageChatbot(language=lang)\n",
    "    response = bot.send_message(question)\n",
    "    print(f\"\\n{response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "## 8. Chatbot with Context Injection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chatbot that can answer questions about specific context/documents\n",
    "class ContextualChatbot:\n",
    "    \"\"\"Chatbot with injected context.\"\"\"\n",
    "    \n",
    "    def __init__(self, context: str = \"\"):\n",
    "        self.context = context\n",
    "        self.model = genai.GenerativeModel('gemini-3-pro')\n",
    "        self.chat = self.model.start_chat(history=[])\n",
    "        \n",
    "        # If context provided, send it first\n",
    "        if context:\n",
    "            self.chat.send_message(f\"Here is some context information:\\n\\n{context}\\n\\nPlease use this information to answer my questions.\")\n",
    "    \n",
    "    def ask(self, question: str) -> str:\n",
    "        \"\"\"Ask a question about the context.\"\"\"\n",
    "        response = self.chat.send_message(question)\n",
    "        return response.text\n",
    "    \n",
    "    def update_context(self, new_context: str):\n",
    "        \"\"\"Update the context.\"\"\"\n",
    "        self.context = new_context\n",
    "        self.chat.send_message(f\"Here is updated context:\\n\\n{new_context}\")\n",
    "\n",
    "# Example usage\n",
    "company_context = \"\"\"\n",
    "TechCorp is a software company founded in 2020.\n",
    "- CEO: Jane Smith\n",
    "- Employees: 150\n",
    "- Main Product: CloudSync - A cloud storage solution\n",
    "- Revenue 2023: $10M\n",
    "- Headquarters: San Francisco, CA\n",
    "\"\"\"\n",
    "\n",
    "bot = ContextualChatbot(context=company_context)\n",
    "\n",
    "questions = [\n",
    "    \"Who is the CEO of TechCorp?\",\n",
    "    \"What is their main product?\",\n",
    "    \"How much revenue did they make in 2023?\",\n",
    "    \"Where is the company located?\"\n",
    "]\n",
    "\n",
    "for q in questions:\n",
    "    print(f\"\\nQ: {q}\")\n",
    "    answer = bot.ask(q)\n",
    "    print(f\"A: {answer}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "## 9. Chatbot Analytics Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chatbot with analytics tracking\n",
    "import time\n",
    "from collections import Counter\n",
    "\n",
    "class AnalyticsChatbot:\n",
    "    \"\"\"Chatbot that tracks usage analytics.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = genai.GenerativeModel('gemini-3-pro')\n",
    "        self.chat = self.model.start_chat(history=[])\n",
    "        self.analytics = {\n",
    "            \"total_messages\": 0,\n",
    "            \"total_tokens\": 0,\n",
    "            \"response_times\": [],\n",
    "            \"message_lengths\": [],\n",
    "            \"topics\": []\n",
    "        }\n",
    "    \n",
    "    def send_message(self, message: str) -> str:\n",
    "        \"\"\"Send message and track analytics.\"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Get response\n",
    "        response = self.chat.send_message(message)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        response_time = time.time() - start_time\n",
    "        message_length = len(message.split())\n",
    "        \n",
    "        # Update analytics\n",
    "        self.analytics[\"total_messages\"] += 1\n",
    "        self.analytics[\"response_times\"].append(response_time)\n",
    "        self.analytics[\"message_lengths\"].append(message_length)\n",
    "        \n",
    "        return response.text\n",
    "    \n",
    "    def get_analytics(self):\n",
    "        \"\"\"Get analytics report.\"\"\"\n",
    "        avg_response_time = sum(self.analytics[\"response_times\"]) / len(self.analytics[\"response_times\"]) if self.analytics[\"response_times\"] else 0\n",
    "        avg_message_length = sum(self.analytics[\"message_lengths\"]) / len(self.analytics[\"message_lengths\"]) if self.analytics[\"message_lengths\"] else 0\n",
    "        \n",
    "        return {\n",
    "            \"Total Messages\": self.analytics[\"total_messages\"],\n",
    "            \"Average Response Time\": f\"{avg_response_time:.2f}s\",\n",
    "            \"Average Message Length\": f\"{avg_message_length:.1f} words\",\n",
    "            \"Fastest Response\": f\"{min(self.analytics['response_times']):.2f}s\" if self.analytics[\"response_times\"] else \"N/A\",\n",
    "            \"Slowest Response\": f\"{max(self.analytics['response_times']):.2f}s\" if self.analytics[\"response_times\"] else \"N/A\"\n",
    "        }\n",
    "\n",
    "# Test analytics\n",
    "analytics_bot = AnalyticsChatbot()\n",
    "\n",
    "# Have a conversation\n",
    "messages = [\n",
    "    \"What is Python?\",\n",
    "    \"Tell me about machine learning\",\n",
    "    \"How do neural networks work?\",\n",
    "    \"Explain deep learning in simple terms\"\n",
    "]\n",
    "\n",
    "for msg in messages:\n",
    "    response = analytics_bot.send_message(msg)\n",
    "    print(f\"User: {msg}\")\n",
    "    print(f\"Bot: {response[:100]}...\\n\")\n",
    "\n",
    "# Display analytics\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CHATBOT ANALYTICS\")\n",
    "print(\"=\"*80)\n",
    "analytics = analytics_bot.get_analytics()\n",
    "for key, value in analytics.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "## 10. Deployment Guide\n",
    "\n",
    "### Deploying to Streamlit Cloud\n",
    "\n",
    "1. **Prepare your repository:**\n",
    "   ```bash\n",
    "   # Create requirements.txt\n",
    "   echo \"streamlit>=1.28.0\" > requirements.txt\n",
    "   echo \"google-generativeai>=0.3.0\" >> requirements.txt\n",
    "   ```\n",
    "\n",
    "2. **Push to GitHub:**\n",
    "   ```bash\n",
    "   git add .\n",
    "   git commit -m \"Add chatbot app\"\n",
    "   git push\n",
    "   ```\n",
    "\n",
    "3. **Deploy on Streamlit Cloud:**\n",
    "   - Go to [share.streamlit.io](https://share.streamlit.io)\n",
    "   - Connect your GitHub repository\n",
    "   - Select your main Python file\n",
    "   - Add `GOOGLE_API_KEY` in Secrets management\n",
    "   - Click Deploy!\n",
    "\n",
    "### Alternative: Deploy on Hugging Face Spaces\n",
    "\n",
    "1. Create a new Space on Hugging Face\n",
    "2. Select Streamlit as the SDK\n",
    "3. Upload your files\n",
    "4. Add API key in Settings â†’ Repository secrets\n",
    "\n",
    "### Best Practices:\n",
    "\n",
    "- âœ… Always use environment variables for API keys\n",
    "- âœ… Add rate limiting for production\n",
    "- âœ… Implement user authentication if needed\n",
    "- âœ… Monitor usage and costs\n",
    "- âœ… Add error handling and logging\n",
    "- âœ… Test thoroughly before deploying"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Explore more advanced applications:\n",
    "- Document Q&A with RAG\n",
    "- Image analysis apps\n",
    "- Multimodal chatbots\n",
    "- Voice-enabled interfaces\n",
    "\n",
    "---\n",
    "\n",
    "## Learn More\n",
    "\n",
    "Build production-ready AI applications with the **[Gen AI Crash Course](https://www.buildfastwithai.com/genai-course)** by Build Fast with AI!\n",
    "\n",
    "**Created by [Build Fast with AI](https://www.buildfastwithai.com)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
