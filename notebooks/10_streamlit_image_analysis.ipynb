{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Streamlit Image Analysis Application\n",
    "\n",
    "> **Created by [Build Fast with AI](https://www.buildfastwithai.com)**\n",
    "\n",
    "This notebook shows you how to build an interactive image analysis application using Streamlit and Gemini 3 Pro's vision capabilities.\n",
    "\n",
    "## What you'll learn:\n",
    "- Working with Gemini's vision API\n",
    "- Building image upload interfaces\n",
    "- Image preprocessing and handling\n",
    "- Multiple analysis modes\n",
    "- Batch image processing\n",
    "- Creating interactive visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## 1. Installation and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q streamlit google-generativeai pillow opencv-python matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "from PIL import Image\n",
    "import io\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure API key\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
    "except:\n",
    "    GOOGLE_API_KEY = os.environ.get('GOOGLE_API_KEY', 'your-api-key-here')\n",
    "\n",
    "genai.configure(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## 2. Basic Image Analysis with Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple test image\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import numpy as np\n",
    "\n",
    "def create_test_image():\n",
    "    \"\"\"Create a test image with shapes and text.\"\"\"\n",
    "    img = Image.new('RGB', (400, 300), color='white')\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    \n",
    "    # Draw shapes\n",
    "    draw.rectangle([50, 50, 150, 150], fill='red', outline='black')\n",
    "    draw.ellipse([200, 50, 300, 150], fill='blue', outline='black')\n",
    "    draw.polygon([100, 200, 150, 250, 50, 250], fill='green', outline='black')\n",
    "    \n",
    "    # Add text\n",
    "    try:\n",
    "        font = ImageFont.truetype(\"/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf\", 20)\n",
    "    except:\n",
    "        font = ImageFont.load_default()\n",
    "    \n",
    "    draw.text((150, 280), \"Test Image\", fill='black', font=font)\n",
    "    \n",
    "    return img\n",
    "\n",
    "test_image = create_test_image()\n",
    "test_image.save('test_image.png')\n",
    "display(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the image\n",
    "model = genai.GenerativeModel('gemini-3-pro')\n",
    "\n",
    "# Load and analyze image\n",
    "img = Image.open('test_image.png')\n",
    "\n",
    "response = model.generate_content([\n",
    "    \"Describe this image in detail. What shapes and colors do you see?\",\n",
    "    img\n",
    "])\n",
    "\n",
    "print(\"Image Analysis:\")\n",
    "print(\"=\" * 80)\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## 3. Different Analysis Modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageAnalyzer:\n",
    "    \"\"\"Analyze images with different modes.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = genai.GenerativeModel('gemini-3-pro')\n",
    "    \n",
    "    def describe(self, image: Image.Image) -> str:\n",
    "        \"\"\"General description of the image.\"\"\"\n",
    "        response = self.model.generate_content([\n",
    "            \"Provide a detailed description of this image.\",\n",
    "            image\n",
    "        ])\n",
    "        return response.text\n",
    "    \n",
    "    def detect_objects(self, image: Image.Image) -> str:\n",
    "        \"\"\"Detect and list objects in the image.\"\"\"\n",
    "        response = self.model.generate_content([\n",
    "            \"List all objects you can identify in this image. Format as a bullet list.\",\n",
    "            image\n",
    "        ])\n",
    "        return response.text\n",
    "    \n",
    "    def extract_text(self, image: Image.Image) -> str:\n",
    "        \"\"\"Extract text from the image (OCR).\"\"\"\n",
    "        response = self.model.generate_content([\n",
    "            \"Extract all text visible in this image. If there's no text, say 'No text found'.\",\n",
    "            image\n",
    "        ])\n",
    "        return response.text\n",
    "    \n",
    "    def analyze_colors(self, image: Image.Image) -> str:\n",
    "        \"\"\"Analyze dominant colors.\"\"\"\n",
    "        response = self.model.generate_content([\n",
    "            \"Identify the dominant colors in this image and describe the color scheme.\",\n",
    "            image\n",
    "        ])\n",
    "        return response.text\n",
    "    \n",
    "    def identify_style(self, image: Image.Image) -> str:\n",
    "        \"\"\"Identify artistic style or genre.\"\"\"\n",
    "        response = self.model.generate_content([\n",
    "            \"Describe the artistic style, mood, and visual characteristics of this image.\",\n",
    "            image\n",
    "        ])\n",
    "        return response.text\n",
    "    \n",
    "    def answer_question(self, image: Image.Image, question: str) -> str:\n",
    "        \"\"\"Answer specific questions about the image.\"\"\"\n",
    "        response = self.model.generate_content([question, image])\n",
    "        return response.text\n",
    "\n",
    "# Test different analysis modes\n",
    "analyzer = ImageAnalyzer()\n",
    "img = Image.open('test_image.png')\n",
    "\n",
    "modes = {\n",
    "    \"Description\": lambda: analyzer.describe(img),\n",
    "    \"Object Detection\": lambda: analyzer.detect_objects(img),\n",
    "    \"Text Extraction\": lambda: analyzer.extract_text(img),\n",
    "    \"Color Analysis\": lambda: analyzer.analyze_colors(img),\n",
    "    \"Style Analysis\": lambda: analyzer.identify_style(img)\n",
    "}\n",
    "\n",
    "for mode_name, mode_func in modes.items():\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"{mode_name}:\")\n",
    "    print(f\"{'='*80}\")\n",
    "    result = mode_func()\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## 4. Basic Streamlit Image Analysis App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save this as image_analysis_basic.py\n",
    "basic_app_code = '''\n",
    "import streamlit as st\n",
    "import google.generativeai as genai\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "st.set_page_config(\n",
    "    page_title=\"Image Analysis\",\n",
    "    page_icon=\"üñºÔ∏è\",\n",
    "    layout=\"wide\"\n",
    ")\n",
    "\n",
    "st.title(\"üñºÔ∏è AI Image Analyzer\")\n",
    "st.caption(\"Upload an image and let AI analyze it\")\n",
    "\n",
    "# API Key\n",
    "api_key = os.environ.get('GOOGLE_API_KEY')\n",
    "if not api_key:\n",
    "    api_key = st.sidebar.text_input(\"Google API Key\", type=\"password\")\n",
    "\n",
    "if api_key:\n",
    "    genai.configure(api_key=api_key)\n",
    "    \n",
    "    # File upload\n",
    "    uploaded_file = st.file_uploader(\n",
    "        \"Choose an image\",\n",
    "        type=[\"jpg\", \"jpeg\", \"png\", \"webp\"]\n",
    "    )\n",
    "    \n",
    "    if uploaded_file:\n",
    "        # Display image\n",
    "        image = Image.open(uploaded_file)\n",
    "        \n",
    "        col1, col2 = st.columns([1, 1])\n",
    "        \n",
    "        with col1:\n",
    "            st.subheader(\"Original Image\")\n",
    "            st.image(image, use_column_width=True)\n",
    "            \n",
    "            # Image info\n",
    "            st.info(f\"Size: {image.size[0]} x {image.size[1]} pixels\")\n",
    "        \n",
    "        with col2:\n",
    "            st.subheader(\"Analysis\")\n",
    "            \n",
    "            # Analysis mode\n",
    "            mode = st.selectbox(\n",
    "                \"Select Analysis Mode\",\n",
    "                [\"Describe Image\", \"Detect Objects\", \"Extract Text\", \"Analyze Colors\", \"Custom Question\"]\n",
    "            )\n",
    "            \n",
    "            if mode == \"Custom Question\":\n",
    "                question = st.text_input(\"Ask about the image:\")\n",
    "            else:\n",
    "                question = None\n",
    "            \n",
    "            if st.button(\"Analyze\", type=\"primary\"):\n",
    "                with st.spinner(\"Analyzing...\"):\n",
    "                    model = genai.GenerativeModel('gemini-3-pro')\n",
    "                    \n",
    "                    prompts = {\n",
    "                        \"Describe Image\": \"Provide a detailed description of this image.\",\n",
    "                        \"Detect Objects\": \"List all objects you can identify in this image.\",\n",
    "                        \"Extract Text\": \"Extract all text from this image. Say 'No text found' if there's none.\",\n",
    "                        \"Analyze Colors\": \"Describe the dominant colors and color scheme of this image.\",\n",
    "                        \"Custom Question\": question if question else \"Describe this image.\"\n",
    "                    }\n",
    "                    \n",
    "                    prompt = prompts[mode]\n",
    "                    response = model.generate_content([prompt, image])\n",
    "                    \n",
    "                    st.success(\"Analysis Complete!\")\n",
    "                    st.markdown(response.text)\n",
    "    else:\n",
    "        st.info(\"üëÜ Upload an image to get started\")\n",
    "        \n",
    "        # Example use cases\n",
    "        st.markdown(\"\"\"\n",
    "        ### What you can do:\n",
    "        - üìù Get detailed image descriptions\n",
    "        - üîç Detect objects and elements\n",
    "        - üìÑ Extract text (OCR)\n",
    "        - üé® Analyze colors and styles\n",
    "        - ‚ùì Ask custom questions about images\n",
    "        \"\"\")\n",
    "else:\n",
    "    st.warning(\"Please enter your API key to start\")\n",
    "'''\n",
    "\n",
    "with open('image_analysis_basic.py', 'w') as f:\n",
    "    f.write(basic_app_code)\n",
    "\n",
    "print(\"Basic image analysis app saved to image_analysis_basic.py\")\n",
    "print(\"\\nTo run: streamlit run image_analysis_basic.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## 5. Advanced Image Analysis App with Multiple Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save this as image_analysis_advanced.py\n",
    "advanced_app_code = '''\n",
    "import streamlit as st\n",
    "import google.generativeai as genai\n",
    "from PIL import Image, ImageEnhance, ImageFilter\n",
    "import os\n",
    "import io\n",
    "\n",
    "st.set_page_config(\n",
    "    page_title=\"Advanced Image Analysis\",\n",
    "    page_icon=\"üé®\",\n",
    "    layout=\"wide\"\n",
    ")\n",
    "\n",
    "# Custom CSS\n",
    "st.markdown(\"\"\"\n",
    "<style>\n",
    "    .main-header {\n",
    "        font-size: 3rem;\n",
    "        font-weight: bold;\n",
    "        color: #1f77b4;\n",
    "        text-align: center;\n",
    "        margin-bottom: 1rem;\n",
    "    }\n",
    "    .stButton>button {\n",
    "        width: 100%;\n",
    "    }\n",
    "</style>\n",
    "\"\"\", unsafe_allow_html=True)\n",
    "\n",
    "st.markdown('<p class=\"main-header\">üé® Advanced AI Image Analyzer</p>', unsafe_allow_html=True)\n",
    "\n",
    "# Sidebar\n",
    "with st.sidebar:\n",
    "    st.header(\"‚öôÔ∏è Settings\")\n",
    "    \n",
    "    api_key = os.environ.get('GOOGLE_API_KEY')\n",
    "    if not api_key:\n",
    "        api_key = st.text_input(\"Google API Key\", type=\"password\")\n",
    "    \n",
    "    st.divider()\n",
    "    \n",
    "    st.subheader(\"Image Preprocessing\")\n",
    "    enable_preprocessing = st.checkbox(\"Enable preprocessing\", value=False)\n",
    "    \n",
    "    if enable_preprocessing:\n",
    "        brightness = st.slider(\"Brightness\", 0.5, 2.0, 1.0, 0.1)\n",
    "        contrast = st.slider(\"Contrast\", 0.5, 2.0, 1.0, 0.1)\n",
    "        sharpness = st.slider(\"Sharpness\", 0.5, 2.0, 1.0, 0.1)\n",
    "    \n",
    "    st.divider()\n",
    "    \n",
    "    st.subheader(\"Analysis Options\")\n",
    "    detail_level = st.select_slider(\n",
    "        \"Detail Level\",\n",
    "        options=[\"Brief\", \"Normal\", \"Detailed\"],\n",
    "        value=\"Normal\"\n",
    "    )\n",
    "\n",
    "def preprocess_image(image, brightness, contrast, sharpness):\n",
    "    \"\"\"Apply image preprocessing.\"\"\"\n",
    "    # Brightness\n",
    "    enhancer = ImageEnhance.Brightness(image)\n",
    "    image = enhancer.enhance(brightness)\n",
    "    \n",
    "    # Contrast\n",
    "    enhancer = ImageEnhance.Contrast(image)\n",
    "    image = enhancer.enhance(contrast)\n",
    "    \n",
    "    # Sharpness\n",
    "    enhancer = ImageEnhance.Sharpness(image)\n",
    "    image = enhancer.enhance(sharpness)\n",
    "    \n",
    "    return image\n",
    "\n",
    "if api_key:\n",
    "    genai.configure(api_key=api_key)\n",
    "    \n",
    "    # Main content\n",
    "    tab1, tab2, tab3 = st.tabs([\"üì§ Single Image\", \"üì¶ Batch Analysis\", \"üîÑ Compare Images\"])\n",
    "    \n",
    "    # Tab 1: Single Image Analysis\n",
    "    with tab1:\n",
    "        uploaded_file = st.file_uploader(\n",
    "            \"Upload an image\",\n",
    "            type=[\"jpg\", \"jpeg\", \"png\", \"webp\"],\n",
    "            key=\"single\"\n",
    "        )\n",
    "        \n",
    "        if uploaded_file:\n",
    "            image = Image.open(uploaded_file)\n",
    "            \n",
    "            # Apply preprocessing if enabled\n",
    "            if enable_preprocessing:\n",
    "                processed_image = preprocess_image(image, brightness, contrast, sharpness)\n",
    "            else:\n",
    "                processed_image = image\n",
    "            \n",
    "            # Display images\n",
    "            col1, col2 = st.columns(2)\n",
    "            \n",
    "            with col1:\n",
    "                st.subheader(\"Image\")\n",
    "                st.image(processed_image, use_column_width=True)\n",
    "                \n",
    "                st.metric(\"Size\", f\"{image.size[0]} x {image.size[1]}\")\n",
    "                st.metric(\"Format\", image.format)\n",
    "            \n",
    "            with col2:\n",
    "                st.subheader(\"Analysis\")\n",
    "                \n",
    "                # Analysis buttons\n",
    "                analysis_types = [\n",
    "                    (\"üîç Describe\", \"Provide a {} description of this image.\"),\n",
    "                    (\"üì¶ Objects\", \"List all objects in this image.\"),\n",
    "                    (\"üìù Text (OCR)\", \"Extract all text from this image.\"),\n",
    "                    (\"üé® Colors\", \"Analyze the color palette and scheme.\"),\n",
    "                    (\"üñºÔ∏è Style\", \"Describe the artistic style and mood.\"),\n",
    "                    (\"üè∑Ô∏è Tags\", \"Generate relevant tags for this image.\")\n",
    "                ]\n",
    "                \n",
    "                col_a, col_b, col_c = st.columns(3)\n",
    "                columns = [col_a, col_b, col_c]\n",
    "                \n",
    "                for idx, (label, prompt_template) in enumerate(analysis_types):\n",
    "                    with columns[idx % 3]:\n",
    "                        if st.button(label, key=f\"btn_{idx}\"):\n",
    "                            with st.spinner(\"Analyzing...\"):\n",
    "                                model = genai.GenerativeModel('gemini-3-pro')\n",
    "                                \n",
    "                                detail_map = {\n",
    "                                    \"Brief\": \"brief\",\n",
    "                                    \"Normal\": \"detailed\",\n",
    "                                    \"Detailed\": \"very detailed\"\n",
    "                                }\n",
    "                                \n",
    "                                prompt = prompt_template.format(detail_map[detail_level])\n",
    "                                response = model.generate_content([prompt, processed_image])\n",
    "                                \n",
    "                                st.session_state.last_result = response.text\n",
    "                \n",
    "                # Custom question\n",
    "                st.divider()\n",
    "                custom_q = st.text_input(\"Ask a custom question:\")\n",
    "                if st.button(\"‚ùì Ask\", key=\"custom_btn\"):\n",
    "                    if custom_q:\n",
    "                        with st.spinner(\"Thinking...\"):\n",
    "                            model = genai.GenerativeModel('gemini-3-pro')\n",
    "                            response = model.generate_content([custom_q, processed_image])\n",
    "                            st.session_state.last_result = response.text\n",
    "                \n",
    "                # Display result\n",
    "                if \"last_result\" in st.session_state:\n",
    "                    st.divider()\n",
    "                    st.markdown(\"### Result:\")\n",
    "                    st.markdown(st.session_state.last_result)\n",
    "    \n",
    "    # Tab 2: Batch Analysis\n",
    "    with tab2:\n",
    "        st.subheader(\"Batch Image Analysis\")\n",
    "        \n",
    "        uploaded_files = st.file_uploader(\n",
    "            \"Upload multiple images\",\n",
    "            type=[\"jpg\", \"jpeg\", \"png\", \"webp\"],\n",
    "            accept_multiple_files=True,\n",
    "            key=\"batch\"\n",
    "        )\n",
    "        \n",
    "        if uploaded_files:\n",
    "            st.write(f\"Uploaded {len(uploaded_files)} images\")\n",
    "            \n",
    "            batch_analysis = st.selectbox(\n",
    "                \"Analysis Type\",\n",
    "                [\"Describe\", \"Objects\", \"Text\", \"Colors\", \"Tags\"]\n",
    "            )\n",
    "            \n",
    "            if st.button(\"Analyze All\", type=\"primary\"):\n",
    "                model = genai.GenerativeModel('gemini-3-pro')\n",
    "                \n",
    "                progress_bar = st.progress(0)\n",
    "                results = []\n",
    "                \n",
    "                for idx, file in enumerate(uploaded_files):\n",
    "                    image = Image.open(file)\n",
    "                    \n",
    "                    prompts = {\n",
    "                        \"Describe\": \"Briefly describe this image.\",\n",
    "                        \"Objects\": \"List objects in this image.\",\n",
    "                        \"Text\": \"Extract text from this image.\",\n",
    "                        \"Colors\": \"Describe the main colors.\",\n",
    "                        \"Tags\": \"Generate 5 tags for this image.\"\n",
    "                    }\n",
    "                    \n",
    "                    response = model.generate_content([prompts[batch_analysis], image])\n",
    "                    results.append((file.name, response.text))\n",
    "                    \n",
    "                    progress_bar.progress((idx + 1) / len(uploaded_files))\n",
    "                \n",
    "                st.success(f\"Analyzed {len(uploaded_files)} images!\")\n",
    "                \n",
    "                # Display results\n",
    "                for name, result in results:\n",
    "                    with st.expander(f\"üìÑ {name}\"):\n",
    "                        st.write(result)\n",
    "    \n",
    "    # Tab 3: Compare Images\n",
    "    with tab3:\n",
    "        st.subheader(\"Compare Two Images\")\n",
    "        \n",
    "        col1, col2 = st.columns(2)\n",
    "        \n",
    "        with col1:\n",
    "            img1 = st.file_uploader(\"First Image\", type=[\"jpg\", \"jpeg\", \"png\"], key=\"img1\")\n",
    "            if img1:\n",
    "                st.image(Image.open(img1), use_column_width=True)\n",
    "        \n",
    "        with col2:\n",
    "            img2 = st.file_uploader(\"Second Image\", type=[\"jpg\", \"jpeg\", \"png\"], key=\"img2\")\n",
    "            if img2:\n",
    "                st.image(Image.open(img2), use_column_width=True)\n",
    "        \n",
    "        if img1 and img2:\n",
    "            if st.button(\"Compare Images\", type=\"primary\"):\n",
    "                with st.spinner(\"Comparing...\"):\n",
    "                    image1 = Image.open(img1)\n",
    "                    image2 = Image.open(img2)\n",
    "                    \n",
    "                    model = genai.GenerativeModel('gemini-3-pro')\n",
    "                    \n",
    "                    # First analysis\n",
    "                    response1 = model.generate_content([\"Describe this image briefly.\", image1])\n",
    "                    response2 = model.generate_content([\"Describe this image briefly.\", image2])\n",
    "                    \n",
    "                    # Comparison\n",
    "                    comparison_prompt = f\"\"\"\n",
    "                    Compare these two images:\n",
    "                    Image 1: {response1.text}\n",
    "                    Image 2: {response2.text}\n",
    "                    \n",
    "                    Provide:\n",
    "                    1. Similarities\n",
    "                    2. Differences\n",
    "                    3. Which is better for what purpose\n",
    "                    \"\"\"\n",
    "                    \n",
    "                    comparison = model.generate_content(comparison_prompt)\n",
    "                    \n",
    "                    st.markdown(\"### Comparison Results:\")\n",
    "                    st.markdown(comparison.text)\n",
    "else:\n",
    "    st.warning(\"Please enter your API key in the sidebar\")\n",
    "'''\n",
    "\n",
    "with open('image_analysis_advanced.py', 'w') as f:\n",
    "    f.write(advanced_app_code)\n",
    "\n",
    "print(\"Advanced image analysis app saved to image_analysis_advanced.py\")\n",
    "print(\"\\nTo run: streamlit run image_analysis_advanced.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## 6. Image Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageComparer:\n",
    "    \"\"\"Compare multiple images.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = genai.GenerativeModel('gemini-3-pro')\n",
    "    \n",
    "    def compare(self, image1: Image.Image, image2: Image.Image) -> dict:\n",
    "        \"\"\"Compare two images.\"\"\"\n",
    "        # Analyze each image\n",
    "        desc1 = self.model.generate_content([\"Describe this image.\", image1])\n",
    "        desc2 = self.model.generate_content([\"Describe this image.\", image2])\n",
    "        \n",
    "        # Compare\n",
    "        comparison_prompt = f\"\"\"\n",
    "        Compare these two images:\n",
    "        \n",
    "        Image 1: {desc1.text}\n",
    "        Image 2: {desc2.text}\n",
    "        \n",
    "        Provide:\n",
    "        - Similarities\n",
    "        - Differences\n",
    "        - Overall comparison\n",
    "        \"\"\"\n",
    "        \n",
    "        comparison = self.model.generate_content(comparison_prompt)\n",
    "        \n",
    "        return {\n",
    "            \"image1_description\": desc1.text,\n",
    "            \"image2_description\": desc2.text,\n",
    "            \"comparison\": comparison.text\n",
    "        }\n",
    "\n",
    "# Test comparison\n",
    "print(\"Image comparison example\")\n",
    "print(\"Create two test images and compare them...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## 7. Image Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageQualityAssessor:\n",
    "    \"\"\"Assess image quality and provide suggestions.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = genai.GenerativeModel('gemini-3-pro')\n",
    "    \n",
    "    def assess_quality(self, image: Image.Image) -> dict:\n",
    "        \"\"\"Assess overall image quality.\"\"\"\n",
    "        prompt = \"\"\"\n",
    "        Assess this image's quality. Consider:\n",
    "        - Clarity and sharpness\n",
    "        - Composition\n",
    "        - Lighting\n",
    "        - Colors\n",
    "        - Overall aesthetic\n",
    "        \n",
    "        Provide a rating (1-10) and suggestions for improvement.\n",
    "        \"\"\"\n",
    "        \n",
    "        response = self.model.generate_content([prompt, image])\n",
    "        return response.text\n",
    "    \n",
    "    def detect_issues(self, image: Image.Image) -> str:\n",
    "        \"\"\"Detect potential issues in the image.\"\"\"\n",
    "        prompt = \"\"\"\n",
    "        Identify any technical or aesthetic issues in this image:\n",
    "        - Blur or lack of focus\n",
    "        - Over/underexposure\n",
    "        - Poor composition\n",
    "        - Color issues\n",
    "        - Any other problems\n",
    "        \"\"\"\n",
    "        \n",
    "        response = self.model.generate_content([prompt, image])\n",
    "        return response.text\n",
    "\n",
    "# Test quality assessment\n",
    "assessor = ImageQualityAssessor()\n",
    "img = Image.open('test_image.png')\n",
    "\n",
    "print(\"Quality Assessment:\")\n",
    "print(\"=\" * 80)\n",
    "quality = assessor.assess_quality(img)\n",
    "print(quality)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "## 8. Image Classification and Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageTagger:\n",
    "    \"\"\"Generate tags and categories for images.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = genai.GenerativeModel('gemini-3-pro')\n",
    "    \n",
    "    def generate_tags(self, image: Image.Image, n_tags: int = 10) -> list:\n",
    "        \"\"\"Generate relevant tags.\"\"\"\n",
    "        prompt = f\"\"\"\n",
    "        Generate {n_tags} relevant tags for this image.\n",
    "        Format as a comma-separated list.\n",
    "        Tags should be specific, descriptive, and useful for search.\n",
    "        \"\"\"\n",
    "        \n",
    "        response = self.model.generate_content([prompt, image])\n",
    "        tags = [tag.strip() for tag in response.text.split(',')]\n",
    "        return tags\n",
    "    \n",
    "    def categorize(self, image: Image.Image) -> dict:\n",
    "        \"\"\"Categorize the image.\"\"\"\n",
    "        prompt = \"\"\"\n",
    "        Categorize this image:\n",
    "        - Main category (e.g., Nature, People, Architecture, etc.)\n",
    "        - Sub-category\n",
    "        - Subject matter\n",
    "        - Occasion/Context (if applicable)\n",
    "        \n",
    "        Format as JSON.\n",
    "        \"\"\"\n",
    "        \n",
    "        response = self.model.generate_content([prompt, image])\n",
    "        return response.text\n",
    "    \n",
    "    def generate_caption(self, image: Image.Image, style: str = \"descriptive\") -> str:\n",
    "        \"\"\"Generate a caption for the image.\"\"\"\n",
    "        style_prompts = {\n",
    "            \"descriptive\": \"Generate a clear, descriptive caption.\",\n",
    "            \"creative\": \"Generate a creative, engaging caption.\",\n",
    "            \"technical\": \"Generate a technical, detailed caption.\",\n",
    "            \"social\": \"Generate a social media ready caption with emojis.\"\n",
    "        }\n",
    "        \n",
    "        prompt = f\"{style_prompts.get(style, style_prompts['descriptive'])}\"\n",
    "        response = self.model.generate_content([prompt, image])\n",
    "        return response.text\n",
    "\n",
    "# Test tagging\n",
    "tagger = ImageTagger()\n",
    "img = Image.open('test_image.png')\n",
    "\n",
    "print(\"Tags:\")\n",
    "tags = tagger.generate_tags(img, n_tags=5)\n",
    "print(\", \".join(tags))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "print(\"Descriptive Caption:\")\n",
    "caption = tagger.generate_caption(img, style=\"descriptive\")\n",
    "print(caption)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "print(\"Creative Caption:\")\n",
    "creative_caption = tagger.generate_caption(img, style=\"creative\")\n",
    "print(creative_caption)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "## 9. Image Search and Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageSearcher:\n",
    "    \"\"\"Search for images based on descriptions.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = genai.GenerativeModel('gemini-3-pro')\n",
    "        self.image_database = []\n",
    "    \n",
    "    def add_image(self, image: Image.Image, metadata: dict = None):\n",
    "        \"\"\"Add an image to the searchable database.\"\"\"\n",
    "        # Generate description\n",
    "        desc = self.model.generate_content([\"Describe this image in detail.\", image])\n",
    "        \n",
    "        self.image_database.append({\n",
    "            \"image\": image,\n",
    "            \"description\": desc.text,\n",
    "            \"metadata\": metadata or {}\n",
    "        })\n",
    "    \n",
    "    def search(self, query: str) -> list:\n",
    "        \"\"\"Search for images matching the query.\"\"\"\n",
    "        results = []\n",
    "        \n",
    "        for idx, item in enumerate(self.image_database):\n",
    "            # Check if description matches query\n",
    "            prompt = f\"\"\"\n",
    "            Does this image description match the search query?\n",
    "            \n",
    "            Description: {item['description']}\n",
    "            Query: {query}\n",
    "            \n",
    "            Answer with just 'Yes' or 'No' and a relevance score (0-10).\n",
    "            \"\"\"\n",
    "            \n",
    "            response = self.model.generate_content(prompt)\n",
    "            \n",
    "            if \"yes\" in response.text.lower():\n",
    "                results.append((idx, item))\n",
    "        \n",
    "        return results\n",
    "\n",
    "print(\"Image search system example created\")\n",
    "print(\"Add images to database and search by natural language queries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "## 10. Best Practices for Image Analysis Apps\n",
    "\n",
    "### Performance Optimization:\n",
    "\n",
    "1. **Image Resizing**: Resize large images before sending to API\n",
    "2. **Caching**: Cache analysis results to avoid repeated API calls\n",
    "3. **Batch Processing**: Process multiple images efficiently\n",
    "4. **Lazy Loading**: Load images only when needed\n",
    "\n",
    "### User Experience:\n",
    "\n",
    "1. **Preview**: Show image previews before analysis\n",
    "2. **Progress Indicators**: Show progress for batch operations\n",
    "3. **Error Handling**: Handle unsupported formats gracefully\n",
    "4. **Export Options**: Allow downloading results\n",
    "\n",
    "### Technical Considerations:\n",
    "\n",
    "1. **File Validation**: Validate file types and sizes\n",
    "2. **Format Support**: Support common image formats (JPEG, PNG, WebP)\n",
    "3. **Memory Management**: Clean up large images after processing\n",
    "4. **Rate Limiting**: Implement API rate limiting\n",
    "\n",
    "### Advanced Features:\n",
    "\n",
    "1. **Image Enhancement**: Offer preprocessing options\n",
    "2. **Batch Export**: Export multiple results at once\n",
    "3. **Comparison Tools**: Compare multiple images\n",
    "4. **Search Functionality**: Search through analyzed images\n",
    "5. **Analytics**: Track usage and popular analysis types\n",
    "\n",
    "### Security:\n",
    "\n",
    "1. **Input Sanitization**: Validate all inputs\n",
    "2. **File Size Limits**: Enforce maximum file sizes\n",
    "3. **Secure Storage**: Don't store sensitive images permanently\n",
    "4. **Privacy**: Clear uploaded images after processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Enhance your image analysis capabilities:\n",
    "- Add video analysis support\n",
    "- Implement image generation features\n",
    "- Build image editing tools\n",
    "- Create image classification models\n",
    "- Integrate with cloud storage services\n",
    "\n",
    "---\n",
    "\n",
    "## Learn More\n",
    "\n",
    "Master computer vision and multimodal AI with the **[Gen AI Crash Course](https://www.buildfastwithai.com/genai-course)** by Build Fast with AI!\n",
    "\n",
    "**Created by [Build Fast with AI](https://www.buildfastwithai.com)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
